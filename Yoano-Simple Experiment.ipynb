{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f86a078-b8f1-4ee4-8c16-dbdd834ed4e7",
      "metadata": {
        "id": "7f86a078-b8f1-4ee4-8c16-dbdd834ed4e7"
      },
      "outputs": [],
      "source": [
        "#**************************************************************************************\n",
        "#\n",
        "#    Title: <YoanoGAN-Experiment>\n",
        "#    Author: <Ege Demir>\n",
        "#    Date: <6/26/1011>\n",
        "#    Code version: <1.0>\n",
        "#\n",
        "#**************************************************************************************\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f65710c-66ba-4de6-90de-2e7d2b5789f5",
      "metadata": {
        "id": "1f65710c-66ba-4de6-90de-2e7d2b5789f5"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import pandas as pd\n",
        "import imageio\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "from tensorflow.keras import layers \n",
        "import time\n",
        "import tensorflow as tf\n",
        "from IPython import display\n",
        "from IPython.display import clear_output\n",
        "from keras.initializers import RandomNormal\n",
        "from PIL import Image\n",
        "from datetime import datetime"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "06b95ed2-79c5-4126-b02d-f6738ca9f38e",
      "metadata": {
        "id": "06b95ed2-79c5-4126-b02d-f6738ca9f38e"
      },
      "source": [
        "# Load and prepare dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "60ec500d-0397-4842-b9d3-54172908154a",
      "metadata": {
        "id": "60ec500d-0397-4842-b9d3-54172908154a"
      },
      "outputs": [],
      "source": [
        "BUFFER_SIZE = 60000\n",
        "BATCH_SIZE = 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8dce3b58-b7ca-4780-a1f8-6646a688569d",
      "metadata": {
        "id": "8dce3b58-b7ca-4780-a1f8-6646a688569d"
      },
      "outputs": [],
      "source": [
        "def generate_dataset(singleClassSize):\n",
        "\n",
        "  classAPoints = np.random.multivariate_normal([1,1], np.eye(2), size=singleClassSize)\n",
        "  classBPoints = np.random.multivariate_normal([-1,-1], np.eye(2), size=singleClassSize)\n",
        "\n",
        "  x = np.append(classAPoints,classBPoints,axis=0)\n",
        "  y = np.append(np.zeros(singleClassSize),np.ones(singleClassSize))\n",
        "\n",
        "  return x,y\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x,y = generate_dataset(1000)"
      ],
      "metadata": {
        "id": "V9fKsSmsn67J"
      },
      "id": "V9fKsSmsn67J",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7916926-d631-44df-b246-930428d2b493",
      "metadata": {
        "id": "c7916926-d631-44df-b246-930428d2b493"
      },
      "outputs": [],
      "source": [
        "y = tf.keras.utils.to_categorical(y, 2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape"
      ],
      "metadata": {
        "id": "N8yUnbq7oNY_",
        "outputId": "d17cd1d7-7fb4-462a-df21-81e4820b1063",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "N8yUnbq7oNY_",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2000, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "0be3524c-cd41-436f-a902-72d247902c0a",
      "metadata": {
        "id": "0be3524c-cd41-436f-a902-72d247902c0a"
      },
      "outputs": [],
      "source": [
        "# Batch and shuffle the data\n",
        "dataset = tf.data.Dataset.from_tensor_slices((x,y)).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "32b2d333-e104-40c8-80e0-6bae57a8a0c6",
      "metadata": {
        "tags": [],
        "id": "32b2d333-e104-40c8-80e0-6bae57a8a0c6"
      },
      "source": [
        "# Custom Layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "1b103a6b-769a-4577-980b-28a048ae0e21",
      "metadata": {
        "id": "1b103a6b-769a-4577-980b-28a048ae0e21"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0d8df3e3-7d2f-4dc4-a999-487ea1882b64",
      "metadata": {
        "tags": [],
        "id": "0d8df3e3-7d2f-4dc4-a999-487ea1882b64"
      },
      "source": [
        "# Custom Models"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "05ca9fa4-8ba5-4e89-b656-b4c96e8e63e8",
      "metadata": {
        "id": "05ca9fa4-8ba5-4e89-b656-b4c96e8e63e8"
      },
      "source": [
        "## Generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "e1f5d16d-029d-4022-b83e-f1177d53df3e",
      "metadata": {
        "id": "e1f5d16d-029d-4022-b83e-f1177d53df3e"
      },
      "outputs": [],
      "source": [
        "def make_generator_model(latent_dim,class_Amt):\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(layers.Dense(16,input_shape=(latent_dim+class_Amt,)))\n",
        "    \n",
        "    for i in range(4):\n",
        "      model.add(layers.Dense(16))\n",
        "      model.add(layers.LeakyReLU(0.1))\n",
        "\n",
        "    \n",
        "    model.add(layers.Dense(2))\n",
        "    assert model.output_shape == (None,2)\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5bc0cf8c-8cc9-40d9-94fb-30f3e97914b3",
      "metadata": {
        "id": "5bc0cf8c-8cc9-40d9-94fb-30f3e97914b3"
      },
      "source": [
        "## Discriminator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "8a35d2b6-ee3a-4076-af59-c9cdbb8ae9e5",
      "metadata": {
        "id": "8a35d2b6-ee3a-4076-af59-c9cdbb8ae9e5"
      },
      "outputs": [],
      "source": [
        "def make_discriminator_model():\n",
        "    model = tf.keras.Sequential()\n",
        "\n",
        "    model.add(layers.Dense(32))\n",
        "    \n",
        "    for i in range(4):\n",
        "      model.add(layers.Dense(32))\n",
        "      model.add(layers.LeakyReLU(0.1))\n",
        "\n",
        "\n",
        "    model.add(layers.Dense(2))\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da8b2062-c630-4348-8618-f2a1b0b0acfd",
      "metadata": {
        "id": "da8b2062-c630-4348-8618-f2a1b0b0acfd"
      },
      "source": [
        "# Define Loss and Optimizers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "8e3b563f-afed-4534-9d5f-f9ea679f1576",
      "metadata": {
        "id": "8e3b563f-afed-4534-9d5f-f9ea679f1576"
      },
      "outputs": [],
      "source": [
        "# This method returns a helper function to compute cross entropy loss\n",
        "cross_entropy_categorical = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
        "cross_entropy_binary = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "b71f9361-8f49-4f89-ba7f-7ca8eaf6efe9",
      "metadata": {
        "id": "b71f9361-8f49-4f89-ba7f-7ca8eaf6efe9"
      },
      "outputs": [],
      "source": [
        "def discriminator_loss(y_pred,y_real):\n",
        "    return cross_entropy_categorical(y_real,y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "6e9069a8-464d-4ba1-a69e-6f37bbf1bd5d",
      "metadata": {
        "id": "6e9069a8-464d-4ba1-a69e-6f37bbf1bd5d"
      },
      "outputs": [],
      "source": [
        "def generator_loss(y_pred,y_real):\n",
        "\n",
        "\n",
        "    # indices = tf.math.argmax(y_real,axis=1)\n",
        "\n",
        "    # arr = []\n",
        "    # for i in range(BATCH_SIZE):\n",
        "    #   arr.append(y_pred[i,indices[i]])\n",
        "\n",
        "    # final_cross_entropy = cross_entropy_binary(tf.zeros_like(indices),arr)\n",
        "\n",
        "    final_cross_entropy = cross_entropy_categorical((tf.ones_like(y_real)-(y_real)),y_pred)\n",
        "    \n",
        "    return final_cross_entropy\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b971de96-fa3e-4f54-b29f-a00e90dc0361",
      "metadata": {
        "id": "b971de96-fa3e-4f54-b29f-a00e90dc0361"
      },
      "source": [
        "# Define Callbacks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "dee572f7-bd43-4ac2-8437-0f50991d8c87",
      "metadata": {
        "id": "dee572f7-bd43-4ac2-8437-0f50991d8c87"
      },
      "outputs": [],
      "source": [
        "logdir = \"logs/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "file_writer = tf.summary.create_file_writer(logdir + \"/metrics\")\n",
        "file_writer.set_as_default()\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
        "    log_dir='logs',\n",
        "    histogram_freq=0,\n",
        "    write_graph=False,\n",
        "    write_images=True,\n",
        "    write_steps_per_second=False,\n",
        "    update_freq=100,\n",
        "    profile_batch=0,\n",
        "    embeddings_freq=0,\n",
        "    embeddings_metadata=None,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "17742300-b393-4f89-8c77-96b8715daeb2",
      "metadata": {
        "id": "17742300-b393-4f89-8c77-96b8715daeb2"
      },
      "source": [
        "# Define training loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "a2b3fc29-a482-4214-8243-84a948862edf",
      "metadata": {
        "id": "a2b3fc29-a482-4214-8243-84a948862edf"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 500\n",
        "noise_dim = 128\n",
        "num_examples_to_generate = 9\n",
        "\n",
        "# You will reuse this seed overtime (so it's easier)\n",
        "# to visualize progress in the animated GIF)\n",
        "\n",
        "rand_y = [0,1,2,3,4,5,6,7,8]\n",
        "rand_y = tf.keras.utils.to_categorical(rand_y, 10)\n",
        "#print(rand_y)\n",
        "#rand_y = np.append(np.ones((num_examples_to_generate,1)),np.zeros((num_examples_to_generate, 9)),axis=1)\n",
        "\n",
        "seed = np.append(rand_y,tf.random.normal([num_examples_to_generate, noise_dim]),axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "a5b95185-1d24-46b9-9546-14fb83f9c0cb",
      "metadata": {
        "id": "a5b95185-1d24-46b9-9546-14fb83f9c0cb"
      },
      "outputs": [],
      "source": [
        "class YoanoGAN(tf.keras.Model):\n",
        "    def __init__(self, discriminator, generator, latent_dim,lmbd=0.7):\n",
        "        super(YoanoGAN, self).__init__()\n",
        "        self.discriminator = discriminator\n",
        "        self.generator = generator\n",
        "        \n",
        "        self.currentBatch = 0\n",
        "        \n",
        "        self.latent_dim = latent_dim\n",
        "        self.lmbd = lmbd\n",
        "        \n",
        "        self.gen_loss_tracker = tf.keras.metrics.Mean(name=\"generator_loss\")\n",
        "        self.disc_loss_tracker = tf.keras.metrics.Mean(name=\"discriminator_loss\")\n",
        "        self.norm_tracker = tf.keras.metrics.Mean(name=\"gen_output_norm\")\n",
        "        self.w_noise_accuracy_tracker = tf.keras.metrics.Mean(name=\"w_noise_accuracy\")\n",
        "        self.wo_noise_accuracy_tracker = tf.keras.metrics.Mean(name=\"wo_noise_accuracy\")\n",
        "        \n",
        "        \n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [self.gen_loss_tracker, self.disc_loss_tracker,self.norm_tracker,self.w_noise_accuracy_tracker,self.wo_noise_accuracy_tracker]\n",
        "    \n",
        "    def get_accuracy(self,x,y_real):\n",
        "        x = tf.cast(x,tf.int64)\n",
        "        y_real = tf.cast(y_real,tf.int64)\n",
        "        \n",
        "        predictions = tf.math.argmax(self.discriminator(x),output_type=tf.dtypes.int64,axis=1)\n",
        "        return (tf.math.count_nonzero(tf.math.argmax(y_real,axis=1)-predictions))/(tf.cast(tf.shape(x)[0],tf.int64))\n",
        "    \n",
        "    def get_norm(self,noise):\n",
        "        norm_calculated = tf.norm(noise,ord=2,axis=[1])\n",
        "        norm_mean = tf.math.reduce_mean(norm_calculated)\n",
        "        return norm_mean\n",
        "    \n",
        "    def compile(self, d_optimizer, g_optimizer, dis_loss_fn, gen_loss_fn):\n",
        "        super(YoanoGAN, self).compile()\n",
        "        self.d_optimizer = d_optimizer\n",
        "        self.g_optimizer = g_optimizer\n",
        "        self.dis_loss_fn = dis_loss_fn\n",
        "        self.gen_loss_fn = gen_loss_fn\n",
        "\n",
        "    def train_step(self, data):\n",
        "        \n",
        "        self.currentBatch = self.currentBatch + 1\n",
        "        \n",
        "        #Import data and infer batch size\n",
        "        x, y = data\n",
        "        BATCH_SIZE = tf.shape(x)[0]\n",
        "        \n",
        "        #Cast x to float32 to match with generator output type (Otherwise adding the two gives an error) \n",
        "        x = tf.cast(x, tf.float32)\n",
        "        \n",
        "        #Append normal noise and one hot labeled y data together for generator input.\n",
        "        gen_in = tf.experimental.numpy.append(y, tf.random.normal([BATCH_SIZE, self.latent_dim]), axis=1)\n",
        "        \n",
        "        with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "            \n",
        "            #Run the generator and generate noises\n",
        "            generated_noise = self.generator(gen_in, training=True)\n",
        "            generated_noise = tf.squeeze(generated_noise * self.lmbd) #Squeezing to remove axis-1 with 1 dimension.\n",
        "            \n",
        "            #Check discriminator output by adding noise and x of dataset.\n",
        "            disc_output = self.discriminator(generated_noise+x, training=True)\n",
        "            \n",
        "            #Calculate loss values for both models.\n",
        "            gen_loss = self.gen_loss_fn(disc_output,y)\n",
        "            disc_loss = self.dis_loss_fn(disc_output,y)\n",
        "            \n",
        "        \n",
        "        #Calculate and apply gradients for both models.\n",
        "        if(True):\n",
        "            gradients_of_generator = gen_tape.gradient(gen_loss, self.generator.trainable_variables)\n",
        "            self.g_optimizer.apply_gradients(zip(gradients_of_generator, self.generator.trainable_variables))\n",
        "    \n",
        "        if(True):\n",
        "            gradients_of_discriminator = disc_tape.gradient(disc_loss, self.discriminator.trainable_variables)\n",
        "            self.d_optimizer.apply_gradients(zip(gradients_of_discriminator, self.discriminator.trainable_variables))\n",
        "        \n",
        "        \n",
        "        \n",
        "        wo_noise_acc = self.get_accuracy(x,y)\n",
        "        w_noise_acc = self.get_accuracy(generated_noise+x,y)\n",
        "        norm = self.get_norm(generated_noise)\n",
        "        \n",
        "        tf.summary.scalar('Generator Loss', data=gen_loss, step=self.currentBatch)\n",
        "        tf.summary.scalar('Discriminator Loss', data=disc_loss, step=self.currentBatch)\n",
        "        tf.summary.scalar('Generator Norm', data=norm, step=self.currentBatch)\n",
        "        tf.summary.scalar('With Noise Accuracy', data=w_noise_acc, step=self.currentBatch)\n",
        "        tf.summary.scalar('Without Noise Accuracy', data=wo_noise_acc, step=self.currentBatch)\n",
        "        \n",
        "        \n",
        "        \n",
        "        #Update and return metrics\n",
        "        self.gen_loss_tracker.update_state(gen_loss)\n",
        "        self.disc_loss_tracker.update_state(disc_loss)\n",
        "        self.norm_tracker.update_state(norm)\n",
        "        self.w_noise_accuracy_tracker.update_state(w_noise_acc)\n",
        "        self.wo_noise_accuracy_tracker.update_state(wo_noise_acc)\n",
        "        return {\n",
        "            \"g_loss\": self.gen_loss_tracker.result(),\n",
        "            \"d_loss\": self.disc_loss_tracker.result(),\n",
        "            \"norm\": self.norm_tracker.result(),\n",
        "            \"With Noise Accuracy\": self.w_noise_accuracy_tracker.result(),\n",
        "            \"Without Noise Accuracy\": self.wo_noise_accuracy_tracker.result()\n",
        "        }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "e6820ea1-3797-4d87-800d-7a549018aa16",
      "metadata": {
        "id": "e6820ea1-3797-4d87-800d-7a549018aa16"
      },
      "outputs": [],
      "source": [
        "generator = make_generator_model(latent_dim=20,class_Amt=2)\n",
        "discriminator = make_discriminator_model()\n",
        "\n",
        "yoano_gan = YoanoGAN(\n",
        "    discriminator=discriminator, generator=generator, latent_dim=20,lmbd=0.7\n",
        ")\n",
        "\n",
        "yoano_gan.compile(\n",
        "    d_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0003),\n",
        "    g_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0003),\n",
        "    dis_loss_fn = discriminator_loss,\n",
        "    gen_loss_fn = generator_loss\n",
        ")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "fe6e4d59-85a3-4043-9c00-7e2b84e40dc5",
      "metadata": {
        "id": "fe6e4d59-85a3-4043-9c00-7e2b84e40dc5"
      },
      "outputs": [],
      "source": [
        "tf.config.run_functions_eagerly(True) #Figure out how to do graph execution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4107b4f-ac33-450b-b964-a66249bbe09b",
      "metadata": {
        "id": "b4107b4f-ac33-450b-b964-a66249bbe09b",
        "outputId": "acee122a-ab3e-483b-9b1b-1ecd5e8ac162"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "468/468 [==============================] - 216s 462ms/step - g_loss: 3.0580 - d_loss: 0.8182 - norm: 8.3959 - With Noise Accuracy: 0.6878 - Without Noise Accuracy: 0.8860\n",
            "Epoch 2/20\n",
            "468/468 [==============================] - 242s 517ms/step - g_loss: 3.8157 - d_loss: 0.7485 - norm: 8.7435 - With Noise Accuracy: 0.6651 - Without Noise Accuracy: 0.8860\n",
            "Epoch 3/20\n",
            "468/468 [==============================] - 232s 495ms/step - g_loss: 4.2413 - d_loss: 0.6673 - norm: 8.0334 - With Noise Accuracy: 0.6762 - Without Noise Accuracy: 0.8867\n",
            "Epoch 4/20\n",
            "468/468 [==============================] - 197s 421ms/step - g_loss: 4.2216 - d_loss: 0.6569 - norm: 8.6582 - With Noise Accuracy: 0.7202 - Without Noise Accuracy: 0.8875\n",
            "Epoch 5/20\n",
            "468/468 [==============================] - 181s 388ms/step - g_loss: 4.4932 - d_loss: 0.6259 - norm: 8.6603 - With Noise Accuracy: 0.7526 - Without Noise Accuracy: 0.8895\n",
            "Epoch 6/20\n",
            "468/468 [==============================] - 204s 436ms/step - g_loss: 4.7440 - d_loss: 0.5856 - norm: 8.3680 - With Noise Accuracy: 0.7913 - Without Noise Accuracy: 0.8924\n",
            "Epoch 7/20\n",
            "468/468 [==============================] - 208s 444ms/step - g_loss: 4.5755 - d_loss: 0.5953 - norm: 7.5264 - With Noise Accuracy: 0.8328 - Without Noise Accuracy: 0.8948\n",
            "Epoch 8/20\n",
            "468/468 [==============================] - 211s 450ms/step - g_loss: 4.7364 - d_loss: 0.5766 - norm: 7.7415 - With Noise Accuracy: 0.8244 - Without Noise Accuracy: 0.8956\n",
            "Epoch 9/20\n",
            "468/468 [==============================] - 207s 441ms/step - g_loss: 4.8013 - d_loss: 0.5566 - norm: 7.9943 - With Noise Accuracy: 0.8429 - Without Noise Accuracy: 0.8899\n",
            "Epoch 10/20\n",
            "468/468 [==============================] - 207s 442ms/step - g_loss: 5.0125 - d_loss: 0.5524 - norm: 8.7320 - With Noise Accuracy: 0.8553 - Without Noise Accuracy: 0.8874\n",
            "Epoch 11/20\n",
            "468/468 [==============================] - 207s 442ms/step - g_loss: 4.9886 - d_loss: 0.5335 - norm: 8.8233 - With Noise Accuracy: 0.8538 - Without Noise Accuracy: 0.8892\n",
            "Epoch 12/20\n",
            "468/468 [==============================] - 208s 444ms/step - g_loss: 5.0730 - d_loss: 0.5151 - norm: 8.8260 - With Noise Accuracy: 0.8696 - Without Noise Accuracy: 0.8970\n",
            "Epoch 13/20\n",
            "468/468 [==============================] - 208s 445ms/step - g_loss: 5.1973 - d_loss: 0.5220 - norm: 8.3428 - With Noise Accuracy: 0.8659 - Without Noise Accuracy: 0.8927\n",
            "Epoch 14/20\n",
            "468/468 [==============================] - 208s 444ms/step - g_loss: 5.3386 - d_loss: 0.4975 - norm: 8.7340 - With Noise Accuracy: 0.8708 - Without Noise Accuracy: 0.8904\n",
            "Epoch 15/20\n",
            "468/468 [==============================] - 207s 442ms/step - g_loss: 5.4454 - d_loss: 0.4867 - norm: 8.6563 - With Noise Accuracy: 0.8663 - Without Noise Accuracy: 0.8934\n",
            "Epoch 16/20\n",
            "468/468 [==============================] - 207s 442ms/step - g_loss: 5.4963 - d_loss: 0.4741 - norm: 8.5511 - With Noise Accuracy: 0.8657 - Without Noise Accuracy: 0.8901\n",
            "Epoch 17/20\n",
            "417/468 [=========================>....] - ETA: 23s - g_loss: 5.7281 - d_loss: 0.4721 - norm: 8.8208 - With Noise Accuracy: 0.8619 - Without Noise Accuracy: 0.8877"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Input \u001b[1;32mIn [31]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43myoano_gan\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
            "File \u001b[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1402\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1403\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1404\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   1405\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[0;32m   1406\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   1407\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m   1408\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1409\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1410\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1411\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
            "File \u001b[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py:1051\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m   1049\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_function\u001b[39m(iterator):\n\u001b[0;32m   1050\u001b[0m   \u001b[38;5;124;03m\"\"\"Runs a training execution with a single step.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1051\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mstep_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py:1040\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.step_function\u001b[1;34m(model, iterator)\u001b[0m\n\u001b[0;32m   1037\u001b[0m   run_step \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mfunction(\n\u001b[0;32m   1038\u001b[0m       run_step, jit_compile\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, reduce_retracing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   1039\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(iterator)\n\u001b[1;32m-> 1040\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribute_strategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1041\u001b[0m outputs \u001b[38;5;241m=\u001b[39m reduce_per_replica(\n\u001b[0;32m   1042\u001b[0m     outputs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_strategy, reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfirst\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m   1043\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
            "File \u001b[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1312\u001b[0m, in \u001b[0;36mStrategyBase.run\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   1307\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscope():\n\u001b[0;32m   1308\u001b[0m   \u001b[38;5;66;03m# tf.distribute supports Eager functions, so AutoGraph should not be\u001b[39;00m\n\u001b[0;32m   1309\u001b[0m   \u001b[38;5;66;03m# applied when the caller is also in Eager mode.\u001b[39;00m\n\u001b[0;32m   1310\u001b[0m   fn \u001b[38;5;241m=\u001b[39m autograph\u001b[38;5;241m.\u001b[39mtf_convert(\n\u001b[0;32m   1311\u001b[0m       fn, autograph_ctx\u001b[38;5;241m.\u001b[39mcontrol_status_ctx(), convert_by_default\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m-> 1312\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_extended\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_for_each_replica\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2888\u001b[0m, in \u001b[0;36mStrategyExtendedV1.call_for_each_replica\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m   2886\u001b[0m   kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m   2887\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_container_strategy()\u001b[38;5;241m.\u001b[39mscope():\n\u001b[1;32m-> 2888\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_for_each_replica\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3689\u001b[0m, in \u001b[0;36m_DefaultDistributionExtended._call_for_each_replica\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m   3687\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call_for_each_replica\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn, args, kwargs):\n\u001b[0;32m   3688\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ReplicaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_container_strategy(), replica_id_in_sync_group\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m-> 3689\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:595\u001b[0m, in \u001b[0;36mcall_with_unspecified_conversion_status.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    593\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    594\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ag_ctx\u001b[38;5;241m.\u001b[39mControlStatusCtx(status\u001b[38;5;241m=\u001b[39mag_ctx\u001b[38;5;241m.\u001b[39mStatus\u001b[38;5;241m.\u001b[39mUNSPECIFIED):\n\u001b[1;32m--> 595\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py:1030\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.step_function.<locals>.run_step\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m   1029\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_step\u001b[39m(data):\n\u001b[1;32m-> 1030\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1031\u001b[0m   \u001b[38;5;66;03m# Ensure counter is updated only if `train_step` succeeds.\u001b[39;00m\n\u001b[0;32m   1032\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mcontrol_dependencies(_minimum_control_deps(outputs)):\n",
            "Input \u001b[1;32mIn [25]\u001b[0m, in \u001b[0;36mYoanoGAN.train_step\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m     60\u001b[0m generated_noise \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39msqueeze(generated_noise \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlmbd) \u001b[38;5;66;03m#Squeezing to remove axis-1 with 1 dimension.\u001b[39;00m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;66;03m#Check discriminator output by adding noise and x of dataset.\u001b[39;00m\n\u001b[1;32m---> 63\u001b[0m disc_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdiscriminator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenerated_noise\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;66;03m#Calculate loss values for both models.\u001b[39;00m\n\u001b[0;32m     66\u001b[0m gen_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgen_loss_fn(disc_output,y)\n",
            "File \u001b[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
            "File \u001b[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py:490\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    486\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(inputs, \u001b[38;5;241m*\u001b[39mcopied_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcopied_kwargs)\n\u001b[0;32m    488\u001b[0m   layout_map_lib\u001b[38;5;241m.\u001b[39m_map_subclass_model_variable(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layout_map)\n\u001b[1;32m--> 490\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
            "File \u001b[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\base_layer.py:1014\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1010\u001b[0m   inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[0;32m   1012\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m autocast_variable\u001b[38;5;241m.\u001b[39menable_auto_cast_variables(\n\u001b[0;32m   1013\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_dtype_object):\n\u001b[1;32m-> 1014\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m call_fn(inputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1016\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_activity_regularizer:\n\u001b[0;32m   1017\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
            "File \u001b[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py:92\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     90\u001b[0m bound_signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 92\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     94\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_keras_call_info_injected\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;66;03m# Only inject info for the innermost failing call\u001b[39;00m\n",
            "File \u001b[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\sequential.py:374\u001b[0m, in \u001b[0;36mSequential.call\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    372\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuilt:\n\u001b[0;32m    373\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_graph_network(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minputs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutputs)\n\u001b[1;32m--> 374\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mSequential\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    376\u001b[0m outputs \u001b[38;5;241m=\u001b[39m inputs  \u001b[38;5;66;03m# handle the corner case where self.layers is empty\u001b[39;00m\n\u001b[0;32m    377\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m    378\u001b[0m   \u001b[38;5;66;03m# During each iteration, `inputs` are the inputs to `layer`, and `outputs`\u001b[39;00m\n\u001b[0;32m    379\u001b[0m   \u001b[38;5;66;03m# are the outputs of `layer` applied to `inputs`. At the end of each\u001b[39;00m\n\u001b[0;32m    380\u001b[0m   \u001b[38;5;66;03m# iteration `inputs` is set to `outputs` to prepare for the next layer.\u001b[39;00m\n",
            "File \u001b[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\functional.py:458\u001b[0m, in \u001b[0;36mFunctional.call\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    439\u001b[0m \u001b[38;5;129m@doc_controls\u001b[39m\u001b[38;5;241m.\u001b[39mdo_not_doc_inheritable\n\u001b[0;32m    440\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    441\u001b[0m   \u001b[38;5;124;03m\"\"\"Calls the model on new inputs.\u001b[39;00m\n\u001b[0;32m    442\u001b[0m \n\u001b[0;32m    443\u001b[0m \u001b[38;5;124;03m  In this case `call` just reapplies\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    456\u001b[0m \u001b[38;5;124;03m      a list of tensors if there are more than one outputs.\u001b[39;00m\n\u001b[0;32m    457\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 458\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_internal_graph\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    459\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\functional.py:596\u001b[0m, in \u001b[0;36mFunctional._run_internal_graph\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    593\u001b[0m   \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# Node is not computable, try skipping.\u001b[39;00m\n\u001b[0;32m    595\u001b[0m args, kwargs \u001b[38;5;241m=\u001b[39m node\u001b[38;5;241m.\u001b[39mmap_arguments(tensor_dict)\n\u001b[1;32m--> 596\u001b[0m outputs \u001b[38;5;241m=\u001b[39m node\u001b[38;5;241m.\u001b[39mlayer(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    598\u001b[0m \u001b[38;5;66;03m# Update tensor_dict.\u001b[39;00m\n\u001b[0;32m    599\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x_id, y \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(node\u001b[38;5;241m.\u001b[39mflat_output_ids, tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mflatten(outputs)):\n",
            "File \u001b[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
            "File \u001b[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\base_layer.py:1014\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1010\u001b[0m   inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[0;32m   1012\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m autocast_variable\u001b[38;5;241m.\u001b[39menable_auto_cast_variables(\n\u001b[0;32m   1013\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_dtype_object):\n\u001b[1;32m-> 1014\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m call_fn(inputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1016\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_activity_regularizer:\n\u001b[0;32m   1017\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
            "File \u001b[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py:92\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     90\u001b[0m bound_signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 92\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     94\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_keras_call_info_injected\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;66;03m# Only inject info for the innermost failing call\u001b[39;00m\n",
            "File \u001b[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\layers\\core\\dense.py:232\u001b[0m, in \u001b[0;36mDense.call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    229\u001b[0m     outputs\u001b[38;5;241m.\u001b[39mset_shape(output_shape)\n\u001b[0;32m    231\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_bias:\n\u001b[1;32m--> 232\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias_add\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    234\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    235\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation(outputs)\n",
            "File \u001b[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
            "File \u001b[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1082\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1080\u001b[0m \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[0;32m   1081\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1082\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m dispatch_target(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1083\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[0;32m   1084\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m   1085\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m   1086\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
            "File \u001b[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py:3523\u001b[0m, in \u001b[0;36mbias_add\u001b[1;34m(value, bias, data_format, name)\u001b[0m\n\u001b[0;32m   3520\u001b[0m   value \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mconvert_to_tensor(value, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   3521\u001b[0m   bias \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mconvert_to_tensor(bias, dtype\u001b[38;5;241m=\u001b[39mvalue\u001b[38;5;241m.\u001b[39mdtype, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbias\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 3523\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgen_nn_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias_add\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_format\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py:673\u001b[0m, in \u001b[0;36mbias_add\u001b[1;34m(value, bias, data_format, name)\u001b[0m\n\u001b[0;32m    671\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[0;32m    672\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 673\u001b[0m     _result \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    674\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mBiasAdd\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_format\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    675\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[0;32m    676\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "yoano_gan.fit(dataset,batch_size=128, epochs=20)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the TensorBoard notebook extension\n",
        "%reload_ext tensorboard"
      ],
      "metadata": {
        "id": "F-EMjxmp7EOU"
      },
      "id": "F-EMjxmp7EOU",
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir logs/scalar"
      ],
      "metadata": {
        "id": "TYMKz1Pw7SOr",
        "outputId": "60217af1-2984-4828-87c8-08bdd2414749",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 821
        }
      },
      "id": "TYMKz1Pw7SOr",
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        (async () => {\n",
              "            const url = new URL(await google.colab.kernel.proxyPort(6007, {'cache': true}));\n",
              "            url.searchParams.set('tensorboardColab', 'true');\n",
              "            const iframe = document.createElement('iframe');\n",
              "            iframe.src = url;\n",
              "            iframe.setAttribute('width', '100%');\n",
              "            iframe.setAttribute('height', '800');\n",
              "            iframe.setAttribute('frameborder', 0);\n",
              "            document.body.appendChild(iframe);\n",
              "        })();\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1361a724-0ab1-497d-a24c-7ffc809c93f1",
      "metadata": {
        "id": "1361a724-0ab1-497d-a24c-7ffc809c93f1",
        "outputId": "cb8ae804-24ca-48a7-e647-c3277245e2ad"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'tf' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# You will reuse this seed overtime (so it's easier)\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# to visualize progress in the animated GIF)\u001b[39;00m\n\u001b[0;32m      8\u001b[0m rand_y \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m5\u001b[39m,\u001b[38;5;241m6\u001b[39m,\u001b[38;5;241m7\u001b[39m,\u001b[38;5;241m8\u001b[39m]\n\u001b[1;32m----> 9\u001b[0m rand_y \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mto_categorical(rand_y, \u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m     11\u001b[0m seed \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mappend(rand_y,tf\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mnormal([num_examples_to_generate, latent_dim]),axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
            "\u001b[1;31mNameError\u001b[0m: name 'tf' is not defined"
          ]
        }
      ],
      "source": [
        "EPOCHS = 500\n",
        "latent_dim = 20\n",
        "num_examples_to_generate = 9\n",
        "\n",
        "# You will reuse this seed overtime (so it's easier)\n",
        "# to visualize progress in the animated GIF)\n",
        "\n",
        "rand_y = [0,1,2,3,4,5,6,7,8]\n",
        "rand_y = tf.keras.utils.to_categorical(rand_y, 10)\n",
        "\n",
        "seed = np.append(rand_y,tf.random.normal([num_examples_to_generate, latent_dim]),axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf34d809-4d5e-4e7d-bf7d-163bd7a2e49c",
      "metadata": {
        "id": "bf34d809-4d5e-4e7d-bf7d-163bd7a2e49c",
        "outputId": "25fa1015-d2d6-4174-d8c4-f5a6da97f940"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'yoano_gan' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m generated_images \u001b[38;5;241m=\u001b[39m \u001b[43myoano_gan\u001b[49m\u001b[38;5;241m.\u001b[39mgenerator(seed) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.7\u001b[39m\n\u001b[0;32m      2\u001b[0m fig \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m7\u001b[39m, \u001b[38;5;241m10\u001b[39m))\n\u001b[0;32m      3\u001b[0m fig\u001b[38;5;241m.\u001b[39msuptitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGenerated Noises\u001b[39m\u001b[38;5;124m'\u001b[39m, fontsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m15\u001b[39m)\n",
            "\u001b[1;31mNameError\u001b[0m: name 'yoano_gan' is not defined"
          ]
        }
      ],
      "source": [
        "generated_images = yoano_gan.generator(seed) * 0.7\n",
        "fig = plt.figure(figsize=(7, 10))\n",
        "fig.suptitle('Generated Noises', fontsize=15)\n",
        "for i in range(generated_images.shape[0]):\n",
        "    plt.subplot(3, 3, i+1)\n",
        "    plt.title(str(i))\n",
        "    plt.imshow(generated_images[i, :, :, 0], cmap='gray',vmin=0, vmax=1)\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.show()\n",
        "np.mean(generated_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e381601-d776-4277-a1b4-69c1bd01203e",
      "metadata": {
        "id": "0e381601-d776-4277-a1b4-69c1bd01203e"
      },
      "outputs": [],
      "source": [
        "def test_model_w_attacker():\n",
        "  #Prepare y values and random values for input to generator\n",
        "  rand_y_in = tf.experimental.numpy.append(test_labels, tf.random.normal([test_labels.shape[0], latent_dim]), axis=1)\n",
        "  \n",
        "  #Generate noises for rand_y_in\n",
        "  generated_noise = yoano_gan.generator(rand_y_in)\n",
        "  generated_noise = generated_noise * 0.7\n",
        "  generated_noise = tf.squeeze(generated_noise)\n",
        "\n",
        "  #Add noises to x images\n",
        "  noisy_images = generated_noise.numpy()+test_images\n",
        "\n",
        "  #Create a new attacker model that has the same architecture as GAN discriminator, and try to fit to noisy x inputs\n",
        "  attacker_model = make_discriminator_model()\n",
        "  attacker_model.compile(optimizer=tf.keras.optimizers.Adam(),loss=cross_entropy_categorical,metrics=[\"accuracy\"])\n",
        "  return attacker_model.fit(noisy_images,test_labels,validation_split=0.3,epochs=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53cd6892-3460-4bb7-9aa7-ff25b4fc086b",
      "metadata": {
        "id": "53cd6892-3460-4bb7-9aa7-ff25b4fc086b",
        "outputId": "ac5047ac-54a3-4ce9-cb38-41bfd9f88e9e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "  1/219 [..............................] - ETA: 21s - loss: 2.3006 - accuracy: 0.0938"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\PC\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:264: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "219/219 [==============================] - 4s 18ms/step - loss: 0.2841 - accuracy: 0.9094 - val_loss: 0.0184 - val_accuracy: 0.9963\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 4s 18ms/step - loss: 0.0122 - accuracy: 0.9964 - val_loss: 0.0147 - val_accuracy: 0.9957\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x1d9eddec280>"
            ]
          },
          "execution_count": 124,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_model_w_attacker()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "464b72dc-c327-4ec4-9330-f7467be76c01",
      "metadata": {
        "id": "464b72dc-c327-4ec4-9330-f7467be76c01"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "name": "Transitional-Yoano.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}