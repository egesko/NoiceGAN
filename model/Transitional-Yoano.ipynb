{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "7f86a078-b8f1-4ee4-8c16-dbdd834ed4e7",
      "metadata": {
        "id": "7f86a078-b8f1-4ee4-8c16-dbdd834ed4e7"
      },
      "outputs": [],
      "source": [
        "#**************************************************************************************\n",
        "#\n",
        "#    Title: <YoanoGAN-OOP Style>\n",
        "#    Author: <Ege Demir>\n",
        "#    Date: <6/26/1011>\n",
        "#    Code version: <0.1>\n",
        "#\n",
        "#**************************************************************************************\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "1f65710c-66ba-4de6-90de-2e7d2b5789f5",
      "metadata": {
        "id": "1f65710c-66ba-4de6-90de-2e7d2b5789f5"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import pandas as pd\n",
        "import imageio\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "from tensorflow.keras import layers \n",
        "import time\n",
        "import tensorflow as tf\n",
        "from IPython import display\n",
        "from IPython.display import clear_output\n",
        "from keras.initializers import RandomNormal\n",
        "from PIL import Image\n",
        "from datetime import datetime\n",
        "import io"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "e79693d4-3d9f-4bce-9980-dd23533cd930",
      "metadata": {
        "id": "e79693d4-3d9f-4bce-9980-dd23533cd930"
      },
      "outputs": [],
      "source": [
        "matplotlib.use('Agg')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "06b95ed2-79c5-4126-b02d-f6738ca9f38e",
      "metadata": {
        "id": "06b95ed2-79c5-4126-b02d-f6738ca9f38e"
      },
      "source": [
        "# Load and prepare dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "60ec500d-0397-4842-b9d3-54172908154a",
      "metadata": {
        "id": "60ec500d-0397-4842-b9d3-54172908154a"
      },
      "outputs": [],
      "source": [
        "BUFFER_SIZE = 60000\n",
        "BATCH_SIZE = 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "8dce3b58-b7ca-4780-a1f8-6646a688569d",
      "metadata": {
        "id": "8dce3b58-b7ca-4780-a1f8-6646a688569d"
      },
      "outputs": [],
      "source": [
        "(train_images, train_labels), (test_images,test_labels) = tf.keras.datasets.mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "c7916926-d631-44df-b246-930428d2b493",
      "metadata": {
        "id": "c7916926-d631-44df-b246-930428d2b493"
      },
      "outputs": [],
      "source": [
        "train_labels = tf.keras.utils.to_categorical(train_labels, 10)\n",
        "test_labels  = tf.keras.utils.to_categorical(test_labels,  10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "f250e6a5-5ecb-45a6-9817-49332941dc07",
      "metadata": {
        "id": "f250e6a5-5ecb-45a6-9817-49332941dc07"
      },
      "outputs": [],
      "source": [
        "amount_to_Cut = int(np.floor((np.ma.size(train_images,axis=0)/BATCH_SIZE))*BATCH_SIZE)\n",
        "\n",
        "train_images = train_images[:amount_to_Cut,:,:]\n",
        "train_labels = train_labels[:amount_to_Cut,:]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "f985b000-556d-42bf-878b-b1be92350d8a",
      "metadata": {
        "id": "f985b000-556d-42bf-878b-b1be92350d8a"
      },
      "outputs": [],
      "source": [
        "train_images = (train_images) / 256  # Normalize the images to [0, 1]\n",
        "train_images = train_images.astype(np.float32)\n",
        "\n",
        "test_images = (test_images) / 256\n",
        "test_images = test_images.astype(np.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "2c262086-2e8e-43f8-9307-7edee14afa3b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "2c262086-2e8e-43f8-9307-7edee14afa3b",
        "outputId": "654582b8-21b2-4ea4-c00e-359c741e3929"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([1., 1., 1., 1., 1., 1., 0., 1., 1., 1.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "image_index = 13\n",
        "plt.plot()\n",
        "plt.imshow(train_images[image_index,:, :], cmap='gray')\n",
        "#(tf.ones_like(train_labels[image_index])-train_labels[image_index])/9\n",
        "tf.ones_like(train_labels[image_index])-(train_labels[image_index])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "0be3524c-cd41-436f-a902-72d247902c0a",
      "metadata": {
        "id": "0be3524c-cd41-436f-a902-72d247902c0a"
      },
      "outputs": [],
      "source": [
        "# Batch and shuffle the data\n",
        "dataset = tf.data.Dataset.from_tensor_slices((train_images,train_labels)).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "#train_Output = tf.data.Dataset.from_tensor_slices(train_labels).batch(BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "32b2d333-e104-40c8-80e0-6bae57a8a0c6",
      "metadata": {
        "tags": [],
        "id": "32b2d333-e104-40c8-80e0-6bae57a8a0c6"
      },
      "source": [
        "# Custom Layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b103a6b-769a-4577-980b-28a048ae0e21",
      "metadata": {
        "id": "1b103a6b-769a-4577-980b-28a048ae0e21"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0d8df3e3-7d2f-4dc4-a999-487ea1882b64",
      "metadata": {
        "tags": [],
        "id": "0d8df3e3-7d2f-4dc4-a999-487ea1882b64"
      },
      "source": [
        "# Custom Models"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "05ca9fa4-8ba5-4e89-b656-b4c96e8e63e8",
      "metadata": {
        "id": "05ca9fa4-8ba5-4e89-b656-b4c96e8e63e8"
      },
      "source": [
        "## Generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "e1f5d16d-029d-4022-b83e-f1177d53df3e",
      "metadata": {
        "id": "e1f5d16d-029d-4022-b83e-f1177d53df3e"
      },
      "outputs": [],
      "source": [
        "def make_generator_model(latent_dim,class_Amt):\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(layers.Dense(7*7*256, use_bias=False, input_shape=(latent_dim+class_Amt,)))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Reshape((7, 7, 256)))\n",
        "    assert model.output_shape == (None, 7, 7, 256)  # Note: None is the batch size\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
        "    assert model.output_shape == (None, 7, 7, 128)\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
        "    assert model.output_shape == (None, 14, 14, 64)\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='sigmoid'))\n",
        "    assert model.output_shape == (None, 28, 28, 1)\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5bc0cf8c-8cc9-40d9-94fb-30f3e97914b3",
      "metadata": {
        "id": "5bc0cf8c-8cc9-40d9-94fb-30f3e97914b3"
      },
      "source": [
        "## Discriminator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "8a35d2b6-ee3a-4076-af59-c9cdbb8ae9e5",
      "metadata": {
        "id": "8a35d2b6-ee3a-4076-af59-c9cdbb8ae9e5"
      },
      "outputs": [],
      "source": [
        "def make_discriminator_model():\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same',\n",
        "                                     input_shape=[28, 28, 1]))\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Dropout(0.3))\n",
        "\n",
        "    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Dropout(0.3))\n",
        "\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(10))\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da8b2062-c630-4348-8618-f2a1b0b0acfd",
      "metadata": {
        "id": "da8b2062-c630-4348-8618-f2a1b0b0acfd"
      },
      "source": [
        "# Define Loss and Optimizers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "8e3b563f-afed-4534-9d5f-f9ea679f1576",
      "metadata": {
        "id": "8e3b563f-afed-4534-9d5f-f9ea679f1576"
      },
      "outputs": [],
      "source": [
        "# This method returns a helper function to compute cross entropy loss\n",
        "cross_entropy_categorical = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
        "cross_entropy_binary = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "b71f9361-8f49-4f89-ba7f-7ca8eaf6efe9",
      "metadata": {
        "id": "b71f9361-8f49-4f89-ba7f-7ca8eaf6efe9"
      },
      "outputs": [],
      "source": [
        "def discriminator_loss(y_pred,y_real):\n",
        "    return cross_entropy_categorical(y_real,y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "6e9069a8-464d-4ba1-a69e-6f37bbf1bd5d",
      "metadata": {
        "id": "6e9069a8-464d-4ba1-a69e-6f37bbf1bd5d"
      },
      "outputs": [],
      "source": [
        "def generator_loss(y_pred,y_real):\n",
        "\n",
        "#     indices = tf.math.argmax(y_real,axis=1)\n",
        "\n",
        "#     arr = []\n",
        "#     for i in range(BATCH_SIZE):\n",
        "#       arr.append(y_pred[i,indices[i]])\n",
        "\n",
        "#     final_cross_entropy = cross_entropy_binary(tf.zeros_like(indices),arr)\n",
        "    \n",
        "    final_cross_entropy = cross_entropy_categorical((tf.ones_like(y_real)-(y_real)),y_pred)\n",
        "    \n",
        "    return final_cross_entropy\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b971de96-fa3e-4f54-b29f-a00e90dc0361",
      "metadata": {
        "id": "b971de96-fa3e-4f54-b29f-a00e90dc0361"
      },
      "source": [
        "# Define Callbacks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "dee572f7-bd43-4ac2-8437-0f50991d8c87",
      "metadata": {
        "id": "dee572f7-bd43-4ac2-8437-0f50991d8c87"
      },
      "outputs": [],
      "source": [
        "logdir = \"logs/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "file_writer = tf.summary.create_file_writer(logdir + \"/metrics\")\n",
        "file_writer.set_as_default()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "17742300-b393-4f89-8c77-96b8715daeb2",
      "metadata": {
        "id": "17742300-b393-4f89-8c77-96b8715daeb2"
      },
      "source": [
        "# Define training loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "a5b95185-1d24-46b9-9546-14fb83f9c0cb",
      "metadata": {
        "id": "a5b95185-1d24-46b9-9546-14fb83f9c0cb"
      },
      "outputs": [],
      "source": [
        "class YoanoGAN(tf.keras.Model):\n",
        "    def __init__(self, discriminator, generator, latent_dim,lmbd=0.7):\n",
        "        super(YoanoGAN, self).__init__()\n",
        "\n",
        "        #Assigning models as class variables\n",
        "        self.discriminator = discriminator\n",
        "        self.generator = generator\n",
        "        \n",
        "        #Initialize batch counter\n",
        "        self.currentBatch = 0\n",
        "        \n",
        "        #Save model hyperparameters\n",
        "        self.latent_dim = latent_dim\n",
        "        self.lmbd = lmbd\n",
        "\n",
        "        \n",
        "        #Fix seed for visualization\n",
        "        self.rand_y = [0,0,0,1,1,1,2,2,2]\n",
        "        fix_labels = tf.keras.utils.to_categorical(self.rand_y, 10)\n",
        "        self.seed = np.append(fix_labels,tf.random.normal([9, latent_dim]),axis=1)\n",
        "        \n",
        "        #Define tracker variables for training metrics\n",
        "        self.gen_loss_tracker = tf.keras.metrics.Mean(name=\"generator_loss\")\n",
        "        self.disc_loss_tracker = tf.keras.metrics.Mean(name=\"discriminator_loss\")\n",
        "        self.norm_tracker = tf.keras.metrics.Mean(name=\"gen_output_norm\")\n",
        "        self.w_noise_accuracy_tracker = tf.keras.metrics.Accuracy(name=\"w_noise_accuracy\")\n",
        "        #self.wo_noise_accuracy_tracker = tf.keras.metrics.Accuracy(name=\"wo_noise_accuracy\")\n",
        "        \n",
        "        \n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [self.gen_loss_tracker, self.disc_loss_tracker,self.norm_tracker,self.w_noise_accuracy_tracker,self.wo_noise_accuracy_tracker]\n",
        "    \n",
        "\n",
        "\n",
        "    #Function for generating noises for visualization in Tensorboard\n",
        "    def save_gen_output(self):\n",
        "        generated_images = self.generator(self.seed) * self.lmbd\n",
        "        fig = plt.figure(figsize=(8, 10))\n",
        "        fig.suptitle('Generated Noises', fontsize=15)\n",
        "        \n",
        "        for i, y in enumerate(self.rand_y):\n",
        "            plt.subplot(3, 3, i+1)\n",
        "            plt.title(str(y))\n",
        "            plt.imshow(generated_images[i, :, :, 0], cmap='gray',vmin=0, vmax=1)\n",
        "            plt.axis('off')\n",
        "            \n",
        "        buf = io.BytesIO()\n",
        "        plt.savefig(buf, format='png')\n",
        "        buf.seek(0)\n",
        "        image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
        "        image = tf.expand_dims(image, 0)\n",
        "        tf.summary.image(\"Generator Output Images\", image, step=self.currentBatch)\n",
        "        plt.close(fig)\n",
        "\n",
        "        \n",
        "    \n",
        "    #Function for calculating norm\n",
        "    def get_norm(self,noise):\n",
        "        norm_calculated = tf.norm(noise,ord=2,axis=[1,2])\n",
        "        norm_mean = tf.math.reduce_mean(norm_calculated)\n",
        "        return norm_mean\n",
        "    \n",
        "    def compile(self, d_optimizer, g_optimizer, dis_loss_fn, gen_loss_fn):\n",
        "        super(YoanoGAN, self).compile()\n",
        "        self.d_optimizer = d_optimizer\n",
        "        self.g_optimizer = g_optimizer\n",
        "        self.dis_loss_fn = dis_loss_fn\n",
        "        self.gen_loss_fn = gen_loss_fn\n",
        "\n",
        "    #Training Step\n",
        "    def train_step(self, data):\n",
        "        \n",
        "        self.currentBatch = self.currentBatch + 1\n",
        "        \n",
        "        #Import data and infer batch size\n",
        "        x, y = data\n",
        "        BATCH_SIZE = tf.shape(x)[0]\n",
        "        \n",
        "        #Cast x to float32 to match with generator output type (Otherwise adding the two gives an error) \n",
        "        x = tf.cast(x, tf.float32)\n",
        "        \n",
        "        #Append normal noise and one hot labeled y data together for generator input.\n",
        "        gen_in = tf.experimental.numpy.append(y, tf.random.normal([BATCH_SIZE, self.latent_dim]), axis=1)\n",
        "        \n",
        "        with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "            \n",
        "            #Run the generator and generate noises\n",
        "            generated_noise = self.generator(gen_in, training=True)\n",
        "            generated_noise = tf.squeeze(generated_noise * self.lmbd) #Squeezing to remove axis-1 with 1 dimension.\n",
        "            \n",
        "            #Check discriminator output by adding noise and x of dataset.\n",
        "            disc_output = self.discriminator(generated_noise+x, training=True)\n",
        "            \n",
        "            #Calculate loss values for both models.\n",
        "            gen_loss = self.gen_loss_fn(disc_output,y)\n",
        "            disc_loss = self.dis_loss_fn(disc_output,y)\n",
        "            \n",
        "        \n",
        "        #Calculate and apply gradients for both models.\n",
        "        if(True):\n",
        "            gradients_of_generator = gen_tape.gradient(gen_loss, self.generator.trainable_variables)\n",
        "            self.g_optimizer.apply_gradients(zip(gradients_of_generator, self.generator.trainable_variables))\n",
        "    \n",
        "        if(True):\n",
        "            gradients_of_discriminator = disc_tape.gradient(disc_loss, self.discriminator.trainable_variables)\n",
        "            self.d_optimizer.apply_gradients(zip(gradients_of_discriminator, self.discriminator.trainable_variables))\n",
        "        \n",
        "        \n",
        "        #Calculate norm of generated noise\n",
        "        norm = self.get_norm(generated_noise)\n",
        "        \n",
        "        #Save noises generated from seeds every 10 batch\n",
        "        if(self.currentBatch % 10 == 0):\n",
        "            self.save_gen_output()\n",
        "        \n",
        "        \n",
        "        \n",
        "        #Update and return metrics\n",
        "        self.gen_loss_tracker.update_state(gen_loss)\n",
        "        self.disc_loss_tracker.update_state(disc_loss)\n",
        "        self.norm_tracker.update_state(norm)\n",
        "        self.w_noise_accuracy_tracker.update_state(tf.argmax(y, axis=1),tf.argmax(disc_output, axis=1))\n",
        "\n",
        "\n",
        "        tf.summary.scalar('Generator Loss', data=self.gen_loss_tracker.result(), step=self.currentBatch)\n",
        "        tf.summary.scalar('Discriminator Loss', data=self.disc_loss_tracker.result(), step=self.currentBatch)\n",
        "        tf.summary.scalar('Generator Norm', data=self.norm_tracker.result(), step=self.currentBatch)\n",
        "        tf.summary.scalar('With Noise Accuracy', data=self.w_noise_accuracy_tracker.result(), step=self.currentBatch)\n",
        "\n",
        "\n",
        "        return {\n",
        "            \"g_loss\": self.gen_loss_tracker.result(),\n",
        "            \"d_loss\": self.disc_loss_tracker.result(),\n",
        "            \"norm\": self.norm_tracker.result(),\n",
        "            \"With Noise Accuracy\": self.w_noise_accuracy_tracker.result()\n",
        "        }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "e6820ea1-3797-4d87-800d-7a549018aa16",
      "metadata": {
        "id": "e6820ea1-3797-4d87-800d-7a549018aa16"
      },
      "outputs": [],
      "source": [
        "generator = make_generator_model(latent_dim=120,class_Amt=10)\n",
        "discriminator = make_discriminator_model()\n",
        "\n",
        "yoano_gan = YoanoGAN(\n",
        "    discriminator=discriminator, generator=generator, latent_dim=120,lmbd=0.8\n",
        ")\n",
        "\n",
        "yoano_gan.compile(\n",
        "    d_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0003),\n",
        "    g_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0003),\n",
        "    dis_loss_fn = discriminator_loss,\n",
        "    gen_loss_fn = generator_loss\n",
        ")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "fe6e4d59-85a3-4043-9c00-7e2b84e40dc5",
      "metadata": {
        "id": "fe6e4d59-85a3-4043-9c00-7e2b84e40dc5"
      },
      "outputs": [],
      "source": [
        "tf.config.run_functions_eagerly(True) #Figure out how to do graph execution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4107b4f-ac33-450b-b964-a66249bbe09b",
      "metadata": {
        "id": "b4107b4f-ac33-450b-b964-a66249bbe09b",
        "outputId": "937e143c-41a5-4f8c-e792-3cf9fd233996"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "468/468 [==============================] - 56s 120ms/step - g_loss: 23.9243 - d_loss: 1.9626 - norm: 9.3047 - With Noise Accuracy: 0.5993 - Without Noise Accuracy: 0.8897\n",
            "Epoch 2/20\n",
            "468/468 [==============================] - 50s 106ms/step - g_loss: 39.0956 - d_loss: 0.9803 - norm: 9.1040 - With Noise Accuracy: 0.5992 - Without Noise Accuracy: 0.8862\n",
            "Epoch 3/20\n",
            "468/468 [==============================] - 52s 111ms/step - g_loss: 58.6819 - d_loss: 0.5211 - norm: 10.8018 - With Noise Accuracy: 0.5097 - Without Noise Accuracy: 0.8880\n",
            "Epoch 4/20\n",
            "161/468 [=========>....................] - ETA: 34s - g_loss: 67.6737 - d_loss: 0.4245 - norm: 11.9095 - With Noise Accuracy: 0.3685 - Without Noise Accuracy: 0.8865"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Input \u001b[1;32mIn [33]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43myoano_gan\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
            "File \u001b[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py:1414\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1412\u001b[0m logs \u001b[38;5;241m=\u001b[39m tmp_logs  \u001b[38;5;66;03m# No error, now safe to assign to logs.\u001b[39;00m\n\u001b[0;32m   1413\u001b[0m end_step \u001b[38;5;241m=\u001b[39m step \u001b[38;5;241m+\u001b[39m data_handler\u001b[38;5;241m.\u001b[39mstep_increment\n\u001b[1;32m-> 1414\u001b[0m \u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_train_batch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mend_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1415\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n\u001b[0;32m   1416\u001b[0m   \u001b[38;5;28;01mbreak\u001b[39;00m\n",
            "File \u001b[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\callbacks.py:438\u001b[0m, in \u001b[0;36mCallbackList.on_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    431\u001b[0m \u001b[38;5;124;03m\"\"\"Calls the `on_train_batch_end` methods of its callbacks.\u001b[39;00m\n\u001b[0;32m    432\u001b[0m \n\u001b[0;32m    433\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m    434\u001b[0m \u001b[38;5;124;03m    batch: Integer, index of batch within the current epoch.\u001b[39;00m\n\u001b[0;32m    435\u001b[0m \u001b[38;5;124;03m    logs: Dict. Aggregated metric results up until this batch.\u001b[39;00m\n\u001b[0;32m    436\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    437\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_call_train_batch_hooks:\n\u001b[1;32m--> 438\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mModeKeys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTRAIN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mend\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\callbacks.py:297\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook\u001b[1;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[0;32m    295\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_batch_begin_hook(mode, batch, logs)\n\u001b[0;32m    296\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m hook \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 297\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_end_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    298\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    299\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    300\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnrecognized hook: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Expected values are [\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbegin\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
            "File \u001b[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\callbacks.py:318\u001b[0m, in \u001b[0;36mCallbackList._call_batch_end_hook\u001b[1;34m(self, mode, batch, logs)\u001b[0m\n\u001b[0;32m    315\u001b[0m   batch_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_start_time\n\u001b[0;32m    316\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times\u001b[38;5;241m.\u001b[39mappend(batch_time)\n\u001b[1;32m--> 318\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhook_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_batches_for_timing_check:\n\u001b[0;32m    321\u001b[0m   end_hook_name \u001b[38;5;241m=\u001b[39m hook_name\n",
            "File \u001b[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\callbacks.py:356\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook_helper\u001b[1;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n\u001b[0;32m    355\u001b[0m   hook \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(callback, hook_name)\n\u001b[1;32m--> 356\u001b[0m   \u001b[43mhook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    358\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_timing:\n\u001b[0;32m    359\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m hook_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hook_times:\n",
            "File \u001b[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\callbacks.py:1034\u001b[0m, in \u001b[0;36mProgbarLogger.on_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1033\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_train_batch_end\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch, logs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m-> 1034\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_update_progbar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\callbacks.py:1107\u001b[0m, in \u001b[0;36mProgbarLogger._batch_update_progbar\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1105\u001b[0m   \u001b[38;5;66;03m# Only block async when verbose = 1.\u001b[39;00m\n\u001b[0;32m   1106\u001b[0m   logs \u001b[38;5;241m=\u001b[39m tf_utils\u001b[38;5;241m.\u001b[39msync_to_numpy_or_python_type(logs)\n\u001b[1;32m-> 1107\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprogbar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlogs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinalize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\generic_utils.py:976\u001b[0m, in \u001b[0;36mProgbar.update\u001b[1;34m(self, current, values, finalize)\u001b[0m\n\u001b[0;32m    973\u001b[0m     info \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    975\u001b[0m   message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m info\n\u001b[1;32m--> 976\u001b[0m   \u001b[43mio_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprint_msg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mline_break\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    977\u001b[0m   message \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    979\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
            "File \u001b[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\io_utils.py:78\u001b[0m, in \u001b[0;36mprint_msg\u001b[1;34m(message, line_break)\u001b[0m\n\u001b[0;32m     76\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     77\u001b[0m     sys\u001b[38;5;241m.\u001b[39mstdout\u001b[38;5;241m.\u001b[39mwrite(message)\n\u001b[1;32m---> 78\u001b[0m   \u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstdout\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflush\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     80\u001b[0m   logging\u001b[38;5;241m.\u001b[39minfo(message)\n",
            "File \u001b[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\ipykernel\\iostream.py:487\u001b[0m, in \u001b[0;36mOutStream.flush\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    485\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpub_thread\u001b[38;5;241m.\u001b[39mschedule(evt\u001b[38;5;241m.\u001b[39mset)\n\u001b[0;32m    486\u001b[0m     \u001b[38;5;66;03m# and give a timeout to avoid\u001b[39;00m\n\u001b[1;32m--> 487\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mevt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflush_timeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    488\u001b[0m         \u001b[38;5;66;03m# write directly to __stderr__ instead of warning because\u001b[39;00m\n\u001b[0;32m    489\u001b[0m         \u001b[38;5;66;03m# if this is happening sys.stderr may be the problem.\u001b[39;00m\n\u001b[0;32m    490\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIOStream.flush timed out\u001b[39m\u001b[38;5;124m\"\u001b[39m, file\u001b[38;5;241m=\u001b[39msys\u001b[38;5;241m.\u001b[39m__stderr__)\n\u001b[0;32m    491\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "File \u001b[1;32m~\\miniconda3\\envs\\tf\\lib\\threading.py:574\u001b[0m, in \u001b[0;36mEvent.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    572\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[0;32m    573\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[1;32m--> 574\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    575\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
            "File \u001b[1;32m~\\miniconda3\\envs\\tf\\lib\\threading.py:316\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    314\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    315\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 316\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    317\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    318\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "yoano_gan.fit(dataset,batch_size=128, epochs=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1361a724-0ab1-497d-a24c-7ffc809c93f1",
      "metadata": {
        "id": "1361a724-0ab1-497d-a24c-7ffc809c93f1"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 500\n",
        "latent_dim = 120\n",
        "num_examples_to_generate = 9\n",
        "\n",
        "# You will reuse this seed overtime (so it's easier)\n",
        "# to visualize progress in the animated GIF)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tensorboard"
      ],
      "metadata": {
        "id": "CZ5jlmduRA0R"
      },
      "id": "CZ5jlmduRA0R"
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the TensorBoard notebook extension\n",
        "%reload_ext tensorboard"
      ],
      "metadata": {
        "id": "F-EMjxmp7EOU"
      },
      "execution_count": 25,
      "outputs": [],
      "id": "F-EMjxmp7EOU"
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --samples_per_plugin=images=500 --logdir logs/scalar"
      ],
      "metadata": {
        "id": "TYMKz1Pw7SOr",
        "outputId": "4c5b8c40-352c-486e-c282-8e8ddf7c6539",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 821
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        (async () => {\n",
              "            const url = new URL(await google.colab.kernel.proxyPort(6006, {'cache': true}));\n",
              "            url.searchParams.set('tensorboardColab', 'true');\n",
              "            const iframe = document.createElement('iframe');\n",
              "            iframe.src = url;\n",
              "            iframe.setAttribute('width', '100%');\n",
              "            iframe.setAttribute('height', '800');\n",
              "            iframe.setAttribute('frameborder', 0);\n",
              "            document.body.appendChild(iframe);\n",
              "        })();\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ],
      "id": "TYMKz1Pw7SOr"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test with Attacker"
      ],
      "metadata": {
        "id": "2RMFqGSqRLM5"
      },
      "id": "2RMFqGSqRLM5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e381601-d776-4277-a1b4-69c1bd01203e",
      "metadata": {
        "id": "0e381601-d776-4277-a1b4-69c1bd01203e"
      },
      "outputs": [],
      "source": [
        "def test_model_w_attacker():\n",
        "  #Prepare y values and random values for input to generator\n",
        "  rand_y_in = tf.experimental.numpy.append(test_labels, tf.random.normal([test_labels.shape[0], latent_dim]), axis=1)\n",
        "  \n",
        "  #Generate noises for rand_y_in\n",
        "  generated_noise = yoano_gan.generator(rand_y_in)\n",
        "  generated_noise = generated_noise * 0.7\n",
        "  generated_noise = tf.squeeze(generated_noise)\n",
        "\n",
        "  #Add noises to x images\n",
        "  noisy_images = generated_noise.numpy()+test_images\n",
        "\n",
        "  #Create a new attacker model that has the same architecture as GAN discriminator, and try to fit to noisy x inputs\n",
        "  attacker_model = make_discriminator_model()\n",
        "  attacker_model.compile(optimizer=tf.keras.optimizers.Adam(),loss=cross_entropy_categorical,metrics=[\"accuracy\"])\n",
        "  return attacker_model.fit(noisy_images,test_labels,validation_split=0.3,epochs=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53cd6892-3460-4bb7-9aa7-ff25b4fc086b",
      "metadata": {
        "id": "53cd6892-3460-4bb7-9aa7-ff25b4fc086b",
        "outputId": "fdcec3d1-11f8-4583-c377-8c69c2aa53e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "219/219 [==============================] - 4s 18ms/step - loss: 0.4252 - accuracy: 0.8719 - val_loss: 0.0118 - val_accuracy: 0.9997\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 4s 18ms/step - loss: 0.0109 - accuracy: 0.9990 - val_loss: 0.0021 - val_accuracy: 1.0000\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x22d68a16820>"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_model_w_attacker()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "name": "Transitional-Yoano.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}