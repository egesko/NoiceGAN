{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "9b898c12-9136-4195-8da9-dfcec6fcc45c",
      "metadata": {
        "id": "9b898c12-9136-4195-8da9-dfcec6fcc45c",
        "outputId": "56d9c151-d720-4ebd-96f6-2e9ed14f30e8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import glob\n",
        "import pandas as pd\n",
        "import imageio\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "from tensorflow.keras import layers\n",
        "import time\n",
        "import tensorflow as tf\n",
        "from IPython import display\n",
        "from IPython.display import clear_output\n",
        "from google.colab import drive\n",
        "from keras.initializers import RandomNormal\n",
        "drive.mount('/content/gdrive')\n",
        "images_dir = '/content/gdrive/MyDrive/NoiceGAN/Test8'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4dc7fcf6-bc9c-4bb2-a687-18f46a859dd0",
      "metadata": {
        "id": "4dc7fcf6-bc9c-4bb2-a687-18f46a859dd0"
      },
      "source": [
        "# Load and prepare dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "D6-1q8AZHL6U"
      },
      "outputs": [],
      "source": [
        "BUFFER_SIZE = 60000\n",
        "BATCH_SIZE = 128"
      ],
      "id": "D6-1q8AZHL6U"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "DSlGzinEHL6W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0269db74-695e-4564-b232-346824e2fb3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "(train_images, train_labels), (test_images,test_labels) = tf.keras.datasets.mnist.load_data()"
      ],
      "id": "DSlGzinEHL6W"
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels = tf.keras.utils.to_categorical(train_labels, 10)\n",
        "test_labels  = tf.keras.utils.to_categorical(test_labels,  10)"
      ],
      "metadata": {
        "id": "o8nizlmPHL6X"
      },
      "execution_count": 7,
      "outputs": [],
      "id": "o8nizlmPHL6X"
    },
    {
      "cell_type": "code",
      "source": [
        "amount_to_Cut = int(np.floor((np.ma.size(train_images,axis=0)/BATCH_SIZE))*BATCH_SIZE)\n",
        "\n",
        "train_images = train_images[:amount_to_Cut,:,:]\n",
        "train_labels = train_labels[:amount_to_Cut,:]\n"
      ],
      "metadata": {
        "id": "N4pGW8hGHL6Z"
      },
      "execution_count": 8,
      "outputs": [],
      "id": "N4pGW8hGHL6Z"
    },
    {
      "cell_type": "code",
      "source": [
        "train_images = (train_images) / 256  # Normalize the images to [0, 1]\n",
        "train_images = train_images.astype(np.float32)\n",
        "\n",
        "test_images = (test_images) / 256\n",
        "test_images = test_images.astype(np.float32)"
      ],
      "metadata": {
        "id": "nhTEmfdeHL6a"
      },
      "execution_count": 9,
      "outputs": [],
      "id": "nhTEmfdeHL6a"
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot()\n",
        "plt.imshow(test_images[10,:, :], cmap='gray')\n",
        "(tf.ones_like(train_labels[10])-train_labels[10])/9"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "outputId": "8761080c-5744-4d5c-9317-741446a05ac5",
        "id": "JbZ_r2EfHL6b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
              "array([0.11111111, 0.11111111, 0.11111111, 0.        , 0.11111111,\n",
              "       0.11111111, 0.11111111, 0.11111111, 0.11111111, 0.11111111],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "id": "JbZ_r2EfHL6b"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "a19856b3-e156-4b71-bca5-c7becc384919",
      "metadata": {
        "id": "a19856b3-e156-4b71-bca5-c7becc384919"
      },
      "outputs": [],
      "source": [
        "# Batch and shuffle the data\n",
        "dataset = tf.data.Dataset.from_tensor_slices((train_images,train_labels)).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "#train_Output = tf.data.Dataset.from_tensor_slices(train_labels).batch(BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7ccd168-0851-4095-8133-8f2ab00893aa",
      "metadata": {
        "id": "e7ccd168-0851-4095-8133-8f2ab00893aa"
      },
      "source": [
        "# Create Models"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "init = RandomNormal(mean=0.0, stddev=0.02)"
      ],
      "metadata": {
        "id": "4pa8a0AxnF8n"
      },
      "id": "4pa8a0AxnF8n",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "1767b2ba-1c4b-4468-9862-4f9e2b665b69",
      "metadata": {
        "id": "1767b2ba-1c4b-4468-9862-4f9e2b665b69"
      },
      "source": [
        "### Generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "fc6901fb-6955-4ce3-b2bc-e022a1444cc3",
      "metadata": {
        "id": "fc6901fb-6955-4ce3-b2bc-e022a1444cc3"
      },
      "outputs": [],
      "source": [
        "def make_generator_model():\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(layers.Dense(7*7*256, use_bias=False, input_shape=(20+10,)))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Reshape((7, 7, 256)))\n",
        "    assert model.output_shape == (None, 7, 7, 256)  # Note: None is the batch size\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
        "    assert model.output_shape == (None, 7, 7, 128)\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
        "    assert model.output_shape == (None, 14, 14, 64)\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='sigmoid'))\n",
        "    assert model.output_shape == (None, 28, 28, 1)\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d9ccb4d2-c3bf-449c-81b8-67be386faba2",
      "metadata": {
        "id": "d9ccb4d2-c3bf-449c-81b8-67be386faba2"
      },
      "source": [
        "### Discriminator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "aa937314-8706-4683-bc3b-2af54cbb07ff",
      "metadata": {
        "id": "aa937314-8706-4683-bc3b-2af54cbb07ff"
      },
      "outputs": [],
      "source": [
        "def make_discriminator_model():\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same',\n",
        "                                     input_shape=[28, 28, 1]))\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Dropout(0.3))\n",
        "\n",
        "    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Dropout(0.3))\n",
        "\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(10))\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "61f99800-9e43-455b-9685-d1e606e9be1b",
      "metadata": {
        "id": "61f99800-9e43-455b-9685-d1e606e9be1b"
      },
      "source": [
        "# Define Loss and Optimizers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "68a2fcc5-7dc7-47f5-9ba7-e3d01ec0320f",
      "metadata": {
        "id": "68a2fcc5-7dc7-47f5-9ba7-e3d01ec0320f"
      },
      "outputs": [],
      "source": [
        "# This method returns a helper function to compute cross entropy loss\n",
        "cross_entropy_categorical = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
        "cross_entropy_binary = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "c8a1a33a-4922-4caa-9e0f-6a97b572b231",
      "metadata": {
        "id": "c8a1a33a-4922-4caa-9e0f-6a97b572b231"
      },
      "outputs": [],
      "source": [
        "def discriminator_loss(y_pred,y_real):\n",
        "    return cross_entropy_categorical(y_real,y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "d7491e96-92b4-4097-91af-0eac8c9babf2",
      "metadata": {
        "id": "d7491e96-92b4-4097-91af-0eac8c9babf2"
      },
      "outputs": [],
      "source": [
        "def generator_loss(y_pred,y_real,gen_out):\n",
        "\n",
        "\n",
        "    indices = tf.math.argmax(y_real,axis=1)\n",
        "\n",
        "    arr = []\n",
        "    for i in range(BATCH_SIZE):\n",
        "      arr.append(y_pred[i,indices[i]])\n",
        "\n",
        "    final_cross_entropy = cross_entropy_binary(tf.zeros_like(indices),arr)\n",
        "\n",
        "    final_cross_entropy = cross_entropy_categorical()\n",
        "    # norm_calculated = tf.norm(gen_out,ord=2,axis=[1,2])\n",
        "    # lp_loss = tf.reduce_mean(norm_calculated)\n",
        "\n",
        "    # final_loss = final_cross_entropy+lambda_parameter*lp_loss\n",
        "    \n",
        "    #--------------------------All Neurons---------------------------------\n",
        "\n",
        "    # # CROSS-ENTROPY-CATEGORICAL\n",
        "    # # There must be a better way to do this, look into it more later!\n",
        "    # mean_tensor_single = tf.math.reduce_mean(y_pred,axis=1)\n",
        "    # mean_tensor_multi = tf.stack([mean_tensor_single,mean_tensor_single,mean_tensor_single,mean_tensor_single,mean_tensor_single,mean_tensor_single,mean_tensor_single,mean_tensor_single,mean_tensor_single,mean_tensor_single],axis=1)\n",
        "    # final_cross_entropy = cross_entropy_categorical(mean_tensor_multi,y_pred)\n",
        "\n",
        "    # #GENERATOR OUTPUT L2 LOSS\n",
        "    # flattened_x = tf.reshape(gen_out,(BATCH_SIZE,28*28))\n",
        "    # norm_calculated = tf.norm(flattened_x,ord=2,axis=1)\n",
        "    # lp_loss = tf.reduce_mean(norm_calculated)\n",
        "\n",
        "    # #SUM OF THE TWO WITH WEIGHT\n",
        "    # final_loss = final_cross_entropy+0.3*lp_loss\n",
        "\n",
        "    #--------------------------Single Neuron---------------------------------\n",
        "\n",
        "    # indices = tf.math.argmax(y_real,axis=1)\n",
        "\n",
        "    # arr = []\n",
        "    # for i in range(BATCH_SIZE):\n",
        "    #   arr.append(y_pred[i,indices[i]])\n",
        "\n",
        "    # mean_tensor_single = tf.math.reduce_mean(y_pred,axis=1)\n",
        "\n",
        "    # final_cross_entropy = cross_entropy_categorical(mean_tensor_single,arr)\n",
        "\n",
        "    # #GENERATOR OUTPUT L2 LOSS\n",
        "    # flattened_x = tf.reshape(gen_out,(BATCH_SIZE,28*28))\n",
        "    # norm_calculated = tf.norm(flattened_x,ord=2,axis=1)\n",
        "    # lp_loss = tf.reduce_mean(norm_calculated)\n",
        "\n",
        "    # #SUM OF THE TWO WITH WEIGHT\n",
        "    # final_loss = final_cross_entropy+0*lp_loss\n",
        "\n",
        "\n",
        "\n",
        "    return final_cross_entropy\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def disc_evaluate(x,y):\n",
        "\n",
        "  predictions = np.argmax(discriminator(x).numpy(),axis=1)\n",
        "  \n",
        "  return 1-((np.count_nonzero(np.argmax(y,axis=1)-predictions))/BATCH_SIZE)"
      ],
      "metadata": {
        "id": "IHYgi0q8fZw-"
      },
      "id": "IHYgi0q8fZw-",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gen_norm_mean(x):\n",
        "  #flattened_x = np.reshape(x,(BATCH_SIZE,28*28))\n",
        "  norm_calculated = tf.norm(x,ord=2,axis=[1,2])\n",
        "  norm_mean = tf.math.reduce_mean(norm_calculated)\n",
        "  return norm_mean.numpy()"
      ],
      "metadata": {
        "id": "x5NI5yGUn_9B"
      },
      "id": "x5NI5yGUn_9B",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "5435e5a5-a891-43b2-8041-d4c14a9ef8ff",
      "metadata": {
        "id": "5435e5a5-a891-43b2-8041-d4c14a9ef8ff"
      },
      "outputs": [],
      "source": [
        "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2eaaed33-0ff9-49db-a25b-287d749fc7b2",
      "metadata": {
        "id": "2eaaed33-0ff9-49db-a25b-287d749fc7b2"
      },
      "source": [
        "# Define training loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "8ccd0a2a-ac70-4cd7-a166-43352d3bf9c5",
      "metadata": {
        "id": "8ccd0a2a-ac70-4cd7-a166-43352d3bf9c5"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 500\n",
        "noise_dim = 20\n",
        "num_examples_to_generate = 9\n",
        "\n",
        "# You will reuse this seed overtime (so it's easier)\n",
        "# to visualize progress in the animated GIF)\n",
        "\n",
        "rand_y = [0,1,2,3,4,5,6,7,8]\n",
        "rand_y = tf.keras.utils.to_categorical(rand_y, 10)\n",
        "#print(rand_y)\n",
        "#rand_y = np.append(np.ones((num_examples_to_generate,1)),np.zeros((num_examples_to_generate, 9)),axis=1)\n",
        "\n",
        "seed = np.append(rand_y,tf.random.normal([num_examples_to_generate, noise_dim]),axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "166f6307-525a-46f3-9cf9-448900600dc6",
      "metadata": {
        "id": "166f6307-525a-46f3-9cf9-448900600dc6"
      },
      "outputs": [],
      "source": [
        "# Notice the use of `tf.function`\n",
        "# This annotation causes the function to be \"compiled\".\n",
        "@tf.function\n",
        "def train_step_only_gen(train_X,train_Y,lambda_norm):\n",
        "    train_X = tf.cast(train_X, tf.float32)\n",
        "    rand_y_in = tf.experimental.numpy.append(train_Y, tf.random.normal([BATCH_SIZE, noise_dim]), axis=1)\n",
        "\n",
        "\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "      \n",
        "      generated_noise = generator(rand_y_in, training=True)\n",
        "      generated_noise = tf.squeeze(generated_noise)\n",
        "      \n",
        "      disc_output = discriminator(generated_noise+train_X, training=True)\n",
        "\n",
        "      gen_loss = generator_loss(disc_output,train_Y,generated_noise)\n",
        "      disc_loss = discriminator_loss(disc_output, train_Y)\n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    #gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "    \n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "    #discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
        "\n",
        "    return gen_loss,disc_loss\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Notice the use of `tf.function`\n",
        "# This annotation causes the function to be \"compiled\".\n",
        "#@tf.function\n",
        "def train_step_together(train_X,train_Y,lambda_norm):\n",
        "    train_X = tf.cast(train_X, tf.float32)\n",
        "    rand_y_in = tf.experimental.numpy.append(train_Y, tf.random.normal([BATCH_SIZE, noise_dim]), axis=1)\n",
        "\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "      \n",
        "      generated_noise = generator(rand_y_in, training=True)\n",
        "      generated_noise = generated_noise * lambda_norm\n",
        "      generated_noise = tf.squeeze(generated_noise)\n",
        "      \n",
        "      disc_output = discriminator(generated_noise+train_X, training=True)\n",
        "\n",
        "      gen_loss = generator_loss(disc_output,train_Y,generated_noise)\n",
        "      disc_loss = discriminator_loss(disc_output, train_Y)\n",
        "\n",
        "    \n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
        "\n",
        "    return gen_loss,disc_loss"
      ],
      "metadata": {
        "id": "GDtmbVOuUjSy"
      },
      "id": "GDtmbVOuUjSy",
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Notice the use of `tf.function`\n",
        "# This annotation causes the function to be \"compiled\".\n",
        "@tf.function\n",
        "def train_step_only_disc(train_X,train_Y,lambda_norm):\n",
        "    train_X = tf.cast(train_X, tf.float32)\n",
        "    rand_y_in = tf.experimental.numpy.append(train_Y, tf.random.normal([BATCH_SIZE, noise_dim]), axis=1)\n",
        "\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "      \n",
        "      generated_noise = generator(rand_y_in, training=True)\n",
        "      generated_noise = tf.squeeze(generated_noise)\n",
        "      \n",
        "      disc_output = discriminator(generated_noise+train_X, training=True)\n",
        "\n",
        "      gen_loss = generator_loss(disc_output,train_Y,generated_noise)\n",
        "      disc_loss = discriminator_loss(disc_output, train_Y)\n",
        "\n",
        "    #gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "    #generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
        "\n",
        "    return gen_loss,disc_loss"
      ],
      "metadata": {
        "id": "yrb9KXciXvmi"
      },
      "id": "yrb9KXciXvmi",
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "db65c45a-8d89-4116-8e8b-7cc613f98ce9",
      "metadata": {
        "id": "db65c45a-8d89-4116-8e8b-7cc613f98ce9"
      },
      "outputs": [],
      "source": [
        "def train(dataset, epochs,train_time,current_lambda):\n",
        "  for epoch in range(epochs):\n",
        "    print(\"epoch: \"+ str(epoch))\n",
        "    gen_loss_sum = 0\n",
        "    disc_loss_sum = 0\n",
        "\n",
        "    start = time.time()\n",
        "\n",
        "    \n",
        "    for x,y in dataset:      \n",
        "      train_time = train_time+1\n",
        "\n",
        "\n",
        "      #Evaluation Metrics:------------------------\n",
        "      rand_in = tf.random.normal([BATCH_SIZE, noise_dim])\n",
        "      x = tf.cast(x, tf.float32)\n",
        "\n",
        "      generated_noise = generator(np.append(y,rand_in,axis=1), training=False)\n",
        "      generated_noise = tf.squeeze(generated_noise)\n",
        "\n",
        "      norm_evals.append(gen_norm_mean(generated_noise))\n",
        "\n",
        "      disc_wo_noise_accuracy.append(disc_evaluate(x,y))\n",
        "      disc_w_noise_accuracy.append(disc_evaluate(x+generated_noise,y))\n",
        "      #--------------------------------------------\n",
        "        \n",
        "\n",
        "      gen_loss,disc_loss = train_step_together(x,y,tf.constant(current_lambda))\n",
        "\n",
        "\n",
        "      gen_loss_sum = gen_loss_sum + gen_loss\n",
        "      disc_loss_sum = disc_loss_sum + disc_loss\n",
        "      gen_loss_evals.append(gen_loss.numpy())\n",
        "      disc_loss_evals.append(disc_loss.numpy())\n",
        "      lambda_evals.append(current_lambda)\n",
        "\n",
        "      if (train_time%3)==0:\n",
        "\n",
        "        clear_output()\n",
        "\n",
        "        print(\"2nd order Norm: \" + str(gen_norm_mean(generated_noise)))\n",
        "        print(\"Discriminator w/o Noise Accuracy: \"+str(disc_evaluate(x,y)))\n",
        "        print(\"Discriminator w/  Noise Accuracy: \"+str(disc_evaluate(x+generated_noise,y)))\n",
        "        print(\"Generator Loss: \"+ str(gen_loss.numpy()))\n",
        "        print(\"Discriminator Loss: \"+ str(disc_loss.numpy()))\n",
        "\n",
        "        plot_metrics(norm_evals,disc_w_noise_accuracy,disc_wo_noise_accuracy,gen_loss_evals,disc_loss_evals,seed,generator,train_time,lambda_evals,current_lambda)\n",
        "      \n",
        "      #if (train_time >= 1000 ):\n",
        "        #return\n",
        "\n",
        "\n",
        "\n",
        "    # Save the model every 5 epochs\n",
        "    if (epoch + 1) % 15 == 0:\n",
        "      checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "\n",
        "    print('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
        "\n",
        "  # Generate after the final epoch\n",
        "  #display.clear_output(wait=True)\n",
        "  #generate_and_save_images(generator,seed)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_metrics(norm_evals,disc_w_noise_accuracy,disc_wo_noise_accuracy,gen_loss_evals,disc_loss_evals,test_input,model,training_step,lambda_evals,lmbd):\n",
        "\n",
        "  # Three subplots sharing both x/y axes\n",
        "  f, (ax1, ax2, ax3, ax4) = plt.subplots(4, sharex=True, sharey=False,figsize=(12,8))\n",
        "\n",
        "  ax1.plot(norm_evals,label=\"Norm\")\n",
        "\n",
        "  ax2.plot(disc_w_noise_accuracy,label=\"w Noise accuracy\")\n",
        "  ax2.plot(disc_wo_noise_accuracy,label=\"wo Noise accuracy\")\n",
        "\n",
        "  ax3.plot(gen_loss_evals,label=\"Gen Loss\")\n",
        "  ax4.plot(disc_loss_evals,label=\"Disc Loss\")\n",
        "\n",
        "\n",
        "  ax1.legend()\n",
        "  ax2.legend()\n",
        "  ax3.legend()\n",
        "  ax4.legend()\n",
        "  \n",
        "  # Fine-tune figure; make subplots close to each other and hide x ticks for\n",
        "  # all but bottom plot.\n",
        "  f.subplots_adjust(hspace=0)\n",
        "  plt.setp([a.get_xticklabels() for a in f.axes[:-1]], visible=False)\n",
        "\n",
        "  plt.savefig(images_dir+'/'+str(lmbd)+'/Graph/'+str(training_step)+'.png')\n",
        "  #---------------------------------------------------------------------------------------------\n",
        "\n",
        "  predictions = model(test_input, training=False) * lmbd\n",
        "\n",
        "  fig = plt.figure(figsize=(7, 10))\n",
        "\n",
        "  for i in range(predictions.shape[0]):\n",
        "      plt.subplot(3, 3, i+1)\n",
        "      plt.imshow(predictions[i, :, :, 0], cmap='gray',vmin=0, vmax=1)\n",
        "      plt.axis('off')\n",
        "\n",
        "    \n",
        "  plt.savefig(images_dir+'/'+str(lmbd)+'/Gen_output/'+str(training_step)+'.png')\n",
        "\n",
        "  \n",
        "\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "SYWrg16Z3LbK"
      },
      "id": "SYWrg16Z3LbK",
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experiment (Test9)"
      ],
      "metadata": {
        "id": "ylvjJS3v-1eR"
      },
      "id": "ylvjJS3v-1eR"
    },
    {
      "cell_type": "code",
      "source": [
        "all_loss = []\n",
        "for lmbd in np.float32(np.linspace(0.9,0.1,9)):\n",
        "\n",
        "  print('----------'+str(lmbd)+'----------')\n",
        "\n",
        "  #Restart graph session\n",
        "  tf.keras.backend.clear_session()\n",
        "\n",
        "  #Generate New Models\n",
        "  generator = make_generator_model()\n",
        "  discriminator = make_discriminator_model()\n",
        "\n",
        "  #Set up optimizer and checkpoints(Never used, putting it here just in case)\n",
        "  checkpoint_dir = './training_checkpoints'\n",
        "  checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "  checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
        "                                  discriminator_optimizer=discriminator_optimizer,\n",
        "                                  generator=generator,\n",
        "                                  discriminator=discriminator)\n",
        "  \n",
        "  #Reset train_time to zero\n",
        "  train_time=0\n",
        "\n",
        "  #Initialize metric save arrays\n",
        "  gen_loss_evals = []\n",
        "  disc_loss_evals = []\n",
        "  loss_for_attacker = []\n",
        "  \n",
        "\n",
        "  #Start training with new lmbd number\n",
        "  min_gen_loss = 100\n",
        "  for x,y in dataset:      \n",
        "      train_time = train_time+1\n",
        "      \n",
        "      gen_loss,disc_loss = train_step_together(x,y,tf.constant(lmbd))\n",
        "\n",
        "      gen_loss_evals.append(gen_loss.numpy())\n",
        "      disc_loss_evals.append(disc_loss.numpy())\n",
        "\n",
        "      if(train_time > 100 and gen_loss_evals[-2]<min_gen_loss and gen_loss_evals[-2]<gen_loss_evals[-1]):\n",
        "        min_gen_loss = gen_loss_evals[-1]\n",
        "        print(\"-----Fitting for attacker: \"+str(train_time)+\"-----Loss:\"+str(min_gen_loss))\n",
        "        history = test_model_w_attacker()\n",
        "        loss_for_attacker.append(history.history['val_loss'][-1])\n",
        "\n",
        "  all_loss.append(np.mean(np.array(loss_for_attacker)))\n",
        "  #Save arrays as csv file\n",
        "  #df = pd.DataFrame(list(zip(norm_evals, disc_w_noise_accuracy,disc_wo_noise_accuracy,gen_loss_evals,disc_loss_evals)),\n",
        "                #columns =['Generator Norm', 'Disc_acc (w/ noise)','Disc_acc (w/o noise)','Generator Loss','Discriminator Loss'])\n",
        "\n",
        "  #df.to_csv(images_dir+'/'+str(lmbd)+'/out.csv',index=False)"
      ],
      "metadata": {
        "id": "mtOI9DOy-IU6",
        "outputId": "54047ddc-0658-4604-ac4a-3a7ff0f47c2a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "mtOI9DOy-IU6",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------0.9----------\n",
            "-----Fitting for attacker: 101-----Loss:0.70019394\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.2967 - accuracy: 0.9139 - val_loss: 0.0125 - val_accuracy: 0.9963\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0098 - accuracy: 0.9981 - val_loss: 0.0138 - val_accuracy: 0.9963\n",
            "-----Fitting for attacker: 104-----Loss:0.74099696\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.2815 - accuracy: 0.9149 - val_loss: 0.0096 - val_accuracy: 0.9980\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0089 - accuracy: 0.9973 - val_loss: 0.0055 - val_accuracy: 0.9983\n",
            "-----Fitting for attacker: 106-----Loss:0.75035834\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.2772 - accuracy: 0.9174 - val_loss: 0.0084 - val_accuracy: 0.9973\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0114 - accuracy: 0.9974 - val_loss: 0.0098 - val_accuracy: 0.9967\n",
            "-----Fitting for attacker: 109-----Loss:0.7267197\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.2678 - accuracy: 0.9177 - val_loss: 0.0124 - val_accuracy: 0.9957\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0101 - accuracy: 0.9976 - val_loss: 0.0057 - val_accuracy: 0.9977\n",
            "-----Fitting for attacker: 126-----Loss:0.75718075\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.3747 - accuracy: 0.8893 - val_loss: 0.0262 - val_accuracy: 0.9907\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0142 - accuracy: 0.9964 - val_loss: 0.0057 - val_accuracy: 0.9987\n",
            "-----Fitting for attacker: 128-----Loss:0.73985296\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.3441 - accuracy: 0.8969 - val_loss: 0.0139 - val_accuracy: 0.9980\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.0121 - accuracy: 0.9969 - val_loss: 0.0048 - val_accuracy: 0.9997\n",
            "-----Fitting for attacker: 131-----Loss:0.66086775\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.3374 - accuracy: 0.8963 - val_loss: 0.0119 - val_accuracy: 0.9980\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0063 - accuracy: 0.9991 - val_loss: 0.0055 - val_accuracy: 0.9983\n",
            "-----Fitting for attacker: 134-----Loss:0.62499976\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.3467 - accuracy: 0.8919 - val_loss: 0.0096 - val_accuracy: 0.9990\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.0080 - accuracy: 0.9983 - val_loss: 0.0036 - val_accuracy: 0.9993\n",
            "-----Fitting for attacker: 136-----Loss:0.63563347\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.2793 - accuracy: 0.9207 - val_loss: 0.0060 - val_accuracy: 0.9990\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0046 - accuracy: 0.9993 - val_loss: 0.0026 - val_accuracy: 0.9997\n",
            "-----Fitting for attacker: 139-----Loss:0.6426633\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.2689 - accuracy: 0.9177 - val_loss: 0.0132 - val_accuracy: 0.9960\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0054 - accuracy: 0.9986 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
            "-----Fitting for attacker: 210-----Loss:0.646801\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.6281 - accuracy: 0.8063 - val_loss: 0.1868 - val_accuracy: 0.9447\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.1461 - accuracy: 0.9539 - val_loss: 0.0819 - val_accuracy: 0.9737\n",
            "-----Fitting for attacker: 212-----Loss:0.6414834\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.6251 - accuracy: 0.8070 - val_loss: 0.1979 - val_accuracy: 0.9383\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.1310 - accuracy: 0.9583 - val_loss: 0.0665 - val_accuracy: 0.9777\n",
            "-----Fitting for attacker: 215-----Loss:0.67642164\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.6313 - accuracy: 0.8081 - val_loss: 0.1405 - val_accuracy: 0.9640\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0909 - accuracy: 0.9723 - val_loss: 0.0365 - val_accuracy: 0.9910\n",
            "-----Fitting for attacker: 217-----Loss:0.65289676\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.6288 - accuracy: 0.8071 - val_loss: 0.1471 - val_accuracy: 0.9593\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.0801 - accuracy: 0.9756 - val_loss: 0.0215 - val_accuracy: 0.9957\n",
            "-----Fitting for attacker: 219-----Loss:0.71220833\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.6141 - accuracy: 0.8109 - val_loss: 0.1027 - val_accuracy: 0.9760\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0477 - accuracy: 0.9884 - val_loss: 0.0268 - val_accuracy: 0.9927\n",
            "-----Fitting for attacker: 225-----Loss:0.74605894\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.5891 - accuracy: 0.8174 - val_loss: 0.1061 - val_accuracy: 0.9660\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0443 - accuracy: 0.9891 - val_loss: 0.0156 - val_accuracy: 0.9963\n",
            "-----Fitting for attacker: 229-----Loss:0.7562787\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.5417 - accuracy: 0.8406 - val_loss: 0.0591 - val_accuracy: 0.9870\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0398 - accuracy: 0.9883 - val_loss: 0.0111 - val_accuracy: 0.9970\n",
            "-----Fitting for attacker: 232-----Loss:0.71756536\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.5041 - accuracy: 0.8441 - val_loss: 0.0647 - val_accuracy: 0.9840\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0478 - accuracy: 0.9864 - val_loss: 0.0205 - val_accuracy: 0.9953\n",
            "-----Fitting for attacker: 234-----Loss:0.7443178\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.4898 - accuracy: 0.8499 - val_loss: 0.0745 - val_accuracy: 0.9770\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0534 - accuracy: 0.9843 - val_loss: 0.0215 - val_accuracy: 0.9947\n",
            "-----Fitting for attacker: 238-----Loss:0.69352734\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.4765 - accuracy: 0.8451 - val_loss: 0.0632 - val_accuracy: 0.9840\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.0593 - accuracy: 0.9836 - val_loss: 0.0272 - val_accuracy: 0.9930\n",
            "-----Fitting for attacker: 240-----Loss:0.7140703\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.4459 - accuracy: 0.8584 - val_loss: 0.0600 - val_accuracy: 0.9817\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.0588 - accuracy: 0.9821 - val_loss: 0.0206 - val_accuracy: 0.9943\n",
            "-----Fitting for attacker: 242-----Loss:0.6764157\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.4437 - accuracy: 0.8636 - val_loss: 0.0708 - val_accuracy: 0.9767\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0543 - accuracy: 0.9827 - val_loss: 0.0179 - val_accuracy: 0.9953\n",
            "-----Fitting for attacker: 288-----Loss:0.48819497\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.4612 - accuracy: 0.8571 - val_loss: 0.0650 - val_accuracy: 0.9817\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0392 - accuracy: 0.9891 - val_loss: 0.0198 - val_accuracy: 0.9940\n",
            "-----Fitting for attacker: 293-----Loss:0.46452197\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.4562 - accuracy: 0.8556 - val_loss: 0.0611 - val_accuracy: 0.9853\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0354 - accuracy: 0.9906 - val_loss: 0.0268 - val_accuracy: 0.9927\n",
            "-----Fitting for attacker: 295-----Loss:0.48027292\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.4246 - accuracy: 0.8624 - val_loss: 0.0552 - val_accuracy: 0.9840\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0416 - accuracy: 0.9890 - val_loss: 0.0299 - val_accuracy: 0.9887\n",
            "-----Fitting for attacker: 403-----Loss:0.5209051\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.5214 - accuracy: 0.8364 - val_loss: 0.0382 - val_accuracy: 0.9897\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0270 - accuracy: 0.9930 - val_loss: 0.0141 - val_accuracy: 0.9960\n",
            "-----Fitting for attacker: 405-----Loss:0.52473277\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.5044 - accuracy: 0.8446 - val_loss: 0.0235 - val_accuracy: 0.9963\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0213 - accuracy: 0.9946 - val_loss: 0.0127 - val_accuracy: 0.9970\n",
            "-----Fitting for attacker: 407-----Loss:0.5187236\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.5005 - accuracy: 0.8433 - val_loss: 0.0296 - val_accuracy: 0.9927\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0161 - accuracy: 0.9967 - val_loss: 0.0052 - val_accuracy: 0.9993\n",
            "-----Fitting for attacker: 410-----Loss:0.49014103\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.5298 - accuracy: 0.8350 - val_loss: 0.0253 - val_accuracy: 0.9947\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0163 - accuracy: 0.9960 - val_loss: 0.0071 - val_accuracy: 0.9987\n",
            "-----Fitting for attacker: 414-----Loss:0.538347\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.4414 - accuracy: 0.8650 - val_loss: 0.0204 - val_accuracy: 0.9943\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0104 - accuracy: 0.9974 - val_loss: 0.0105 - val_accuracy: 0.9977\n",
            "-----Fitting for attacker: 418-----Loss:0.5642136\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.4547 - accuracy: 0.8579 - val_loss: 0.0134 - val_accuracy: 0.9983\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0078 - accuracy: 0.9984 - val_loss: 0.0042 - val_accuracy: 0.9997\n",
            "----------0.8----------\n",
            "-----Fitting for attacker: 101-----Loss:0.6355727\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.3930 - accuracy: 0.8773 - val_loss: 0.0461 - val_accuracy: 0.9883\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.0328 - accuracy: 0.9909 - val_loss: 0.0236 - val_accuracy: 0.9930\n",
            "-----Fitting for attacker: 103-----Loss:0.6861856\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.3790 - accuracy: 0.8803 - val_loss: 0.0580 - val_accuracy: 0.9810\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0369 - accuracy: 0.9896 - val_loss: 0.0166 - val_accuracy: 0.9957\n",
            "-----Fitting for attacker: 105-----Loss:0.67633796\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.3828 - accuracy: 0.8774 - val_loss: 0.0483 - val_accuracy: 0.9863\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0281 - accuracy: 0.9940 - val_loss: 0.0185 - val_accuracy: 0.9930\n",
            "-----Fitting for attacker: 125-----Loss:0.7716289\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.3699 - accuracy: 0.8891 - val_loss: 0.0505 - val_accuracy: 0.9847\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0235 - accuracy: 0.9943 - val_loss: 0.0234 - val_accuracy: 0.9917\n",
            "-----Fitting for attacker: 128-----Loss:0.54875416\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.3631 - accuracy: 0.8916 - val_loss: 0.0468 - val_accuracy: 0.9877\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0213 - accuracy: 0.9934 - val_loss: 0.0191 - val_accuracy: 0.9937\n",
            "-----Fitting for attacker: 132-----Loss:0.46924728\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.2872 - accuracy: 0.9126 - val_loss: 0.0222 - val_accuracy: 0.9950\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0155 - accuracy: 0.9956 - val_loss: 0.0107 - val_accuracy: 0.9977\n",
            "-----Fitting for attacker: 135-----Loss:0.39592192\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.2915 - accuracy: 0.9126 - val_loss: 0.0186 - val_accuracy: 0.9933\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.0137 - accuracy: 0.9961 - val_loss: 0.0207 - val_accuracy: 0.9927\n",
            "----------0.7----------\n",
            "-----Fitting for attacker: 101-----Loss:0.7439914\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.3286 - accuracy: 0.8973 - val_loss: 0.0125 - val_accuracy: 0.9977\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0081 - accuracy: 0.9984 - val_loss: 0.0048 - val_accuracy: 0.9983\n",
            "-----Fitting for attacker: 103-----Loss:0.7429244\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.3328 - accuracy: 0.8993 - val_loss: 0.0154 - val_accuracy: 0.9963\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0079 - accuracy: 0.9984 - val_loss: 0.0048 - val_accuracy: 0.9983\n",
            "-----Fitting for attacker: 132-----Loss:0.7587078\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.3416 - accuracy: 0.8950 - val_loss: 0.0613 - val_accuracy: 0.9823\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.0457 - accuracy: 0.9866 - val_loss: 0.0373 - val_accuracy: 0.9870\n",
            "-----Fitting for attacker: 135-----Loss:0.7198535\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.3496 - accuracy: 0.8973 - val_loss: 0.0503 - val_accuracy: 0.9860\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0407 - accuracy: 0.9871 - val_loss: 0.0269 - val_accuracy: 0.9923\n",
            "-----Fitting for attacker: 138-----Loss:0.6525693\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.3297 - accuracy: 0.8950 - val_loss: 0.0715 - val_accuracy: 0.9763\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0421 - accuracy: 0.9873 - val_loss: 0.0382 - val_accuracy: 0.9897\n",
            "-----Fitting for attacker: 140-----Loss:0.5711069\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.3517 - accuracy: 0.8903 - val_loss: 0.0540 - val_accuracy: 0.9837\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0353 - accuracy: 0.9899 - val_loss: 0.0255 - val_accuracy: 0.9913\n",
            "-----Fitting for attacker: 145-----Loss:0.53947747\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.2993 - accuracy: 0.9080 - val_loss: 0.0251 - val_accuracy: 0.9937\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0218 - accuracy: 0.9931 - val_loss: 0.0178 - val_accuracy: 0.9953\n",
            "-----Fitting for attacker: 149-----Loss:0.6027822\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.2675 - accuracy: 0.9243 - val_loss: 0.0119 - val_accuracy: 0.9967\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0112 - accuracy: 0.9963 - val_loss: 0.0034 - val_accuracy: 0.9990\n",
            "-----Fitting for attacker: 151-----Loss:0.6397308\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.2294 - accuracy: 0.9351 - val_loss: 0.0067 - val_accuracy: 0.9987\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0081 - accuracy: 0.9979 - val_loss: 0.0023 - val_accuracy: 0.9993\n",
            "-----Fitting for attacker: 252-----Loss:0.655856\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.3467 - accuracy: 0.8874 - val_loss: 0.0326 - val_accuracy: 0.9907\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0366 - accuracy: 0.9879 - val_loss: 0.0122 - val_accuracy: 0.9963\n",
            "-----Fitting for attacker: 254-----Loss:0.61985004\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.3241 - accuracy: 0.9001 - val_loss: 0.0372 - val_accuracy: 0.9897\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.0340 - accuracy: 0.9894 - val_loss: 0.0205 - val_accuracy: 0.9950\n",
            "-----Fitting for attacker: 257-----Loss:0.60479534\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.3600 - accuracy: 0.8884 - val_loss: 0.0295 - val_accuracy: 0.9933\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0267 - accuracy: 0.9923 - val_loss: 0.0233 - val_accuracy: 0.9920\n",
            "-----Fitting for attacker: 261-----Loss:0.6053159\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.3298 - accuracy: 0.8981 - val_loss: 0.0371 - val_accuracy: 0.9900\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0241 - accuracy: 0.9931 - val_loss: 0.0134 - val_accuracy: 0.9960\n",
            "-----Fitting for attacker: 265-----Loss:0.6219264\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.3102 - accuracy: 0.9039 - val_loss: 0.0285 - val_accuracy: 0.9917\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0215 - accuracy: 0.9944 - val_loss: 0.0202 - val_accuracy: 0.9940\n",
            "-----Fitting for attacker: 268-----Loss:0.67044723\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.2815 - accuracy: 0.9156 - val_loss: 0.0225 - val_accuracy: 0.9927\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0185 - accuracy: 0.9951 - val_loss: 0.0285 - val_accuracy: 0.9900\n",
            "-----Fitting for attacker: 271-----Loss:0.6952788\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.2707 - accuracy: 0.9220 - val_loss: 0.0231 - val_accuracy: 0.9947\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0142 - accuracy: 0.9961 - val_loss: 0.0068 - val_accuracy: 0.9983\n",
            "-----Fitting for attacker: 273-----Loss:0.6935681\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.2684 - accuracy: 0.9180 - val_loss: 0.0254 - val_accuracy: 0.9923\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0212 - accuracy: 0.9924 - val_loss: 0.0081 - val_accuracy: 0.9973\n",
            "-----Fitting for attacker: 275-----Loss:0.73357826\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.2687 - accuracy: 0.9163 - val_loss: 0.0174 - val_accuracy: 0.9963\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0186 - accuracy: 0.9939 - val_loss: 0.0052 - val_accuracy: 0.9990\n",
            "-----Fitting for attacker: 310-----Loss:0.72214836\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.3598 - accuracy: 0.8853 - val_loss: 0.0292 - val_accuracy: 0.9900\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0204 - accuracy: 0.9946 - val_loss: 0.0151 - val_accuracy: 0.9960\n",
            "-----Fitting for attacker: 314-----Loss:0.6639493\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.3400 - accuracy: 0.8946 - val_loss: 0.0324 - val_accuracy: 0.9903\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0205 - accuracy: 0.9946 - val_loss: 0.0222 - val_accuracy: 0.9913\n",
            "-----Fitting for attacker: 318-----Loss:0.65306383\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.3526 - accuracy: 0.8910 - val_loss: 0.0204 - val_accuracy: 0.9940\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0162 - accuracy: 0.9953 - val_loss: 0.0247 - val_accuracy: 0.9913\n",
            "-----Fitting for attacker: 320-----Loss:0.6651684\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 8ms/step - loss: 0.3426 - accuracy: 0.8971 - val_loss: 0.0504 - val_accuracy: 0.9837\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0201 - accuracy: 0.9940 - val_loss: 0.0228 - val_accuracy: 0.9927\n",
            "-----Fitting for attacker: 324-----Loss:0.6715067\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.3375 - accuracy: 0.8951 - val_loss: 0.0575 - val_accuracy: 0.9803\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0227 - accuracy: 0.9941 - val_loss: 0.0214 - val_accuracy: 0.9950\n",
            "-----Fitting for attacker: 328-----Loss:0.65884995\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.3190 - accuracy: 0.9007 - val_loss: 0.0224 - val_accuracy: 0.9933\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0181 - accuracy: 0.9947 - val_loss: 0.0230 - val_accuracy: 0.9920\n",
            "-----Fitting for attacker: 334-----Loss:0.6487238\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.3132 - accuracy: 0.9037 - val_loss: 0.0242 - val_accuracy: 0.9937\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0143 - accuracy: 0.9960 - val_loss: 0.0124 - val_accuracy: 0.9960\n",
            "-----Fitting for attacker: 400-----Loss:0.6410415\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.2602 - accuracy: 0.9189 - val_loss: 0.0093 - val_accuracy: 0.9973\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0048 - accuracy: 0.9987 - val_loss: 0.0065 - val_accuracy: 0.9983\n",
            "-----Fitting for attacker: 403-----Loss:0.6583512\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.2409 - accuracy: 0.9259 - val_loss: 0.0051 - val_accuracy: 0.9997\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0064 - accuracy: 0.9987 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
            "-----Fitting for attacker: 408-----Loss:0.60665715\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.2423 - accuracy: 0.9239 - val_loss: 0.0193 - val_accuracy: 0.9947\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0052 - accuracy: 0.9989 - val_loss: 0.0049 - val_accuracy: 0.9987\n",
            "-----Fitting for attacker: 410-----Loss:0.62853\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.2332 - accuracy: 0.9324 - val_loss: 0.0068 - val_accuracy: 0.9990\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0059 - accuracy: 0.9987 - val_loss: 0.0044 - val_accuracy: 0.9997\n",
            "-----Fitting for attacker: 413-----Loss:0.579605\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.2417 - accuracy: 0.9293 - val_loss: 0.0110 - val_accuracy: 0.9973\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0097 - accuracy: 0.9970 - val_loss: 0.0041 - val_accuracy: 0.9990\n",
            "-----Fitting for attacker: 416-----Loss:0.57214236\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.2268 - accuracy: 0.9330 - val_loss: 0.0057 - val_accuracy: 0.9990\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0094 - accuracy: 0.9973 - val_loss: 0.0054 - val_accuracy: 0.9987\n",
            "-----Fitting for attacker: 423-----Loss:0.5630571\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.2333 - accuracy: 0.9303 - val_loss: 0.0067 - val_accuracy: 0.9983\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0081 - accuracy: 0.9974 - val_loss: 0.0035 - val_accuracy: 0.9997\n",
            "-----Fitting for attacker: 452-----Loss:0.5682483\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.2679 - accuracy: 0.9174 - val_loss: 0.0140 - val_accuracy: 0.9963\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0081 - accuracy: 0.9980 - val_loss: 0.0056 - val_accuracy: 0.9983\n",
            "-----Fitting for attacker: 460-----Loss:0.5697819\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.3105 - accuracy: 0.9056 - val_loss: 0.0269 - val_accuracy: 0.9923\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0110 - accuracy: 0.9977 - val_loss: 0.0111 - val_accuracy: 0.9967\n",
            "-----Fitting for attacker: 463-----Loss:0.57367647\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.3187 - accuracy: 0.9029 - val_loss: 0.0192 - val_accuracy: 0.9967\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0090 - accuracy: 0.9980 - val_loss: 0.0040 - val_accuracy: 0.9990\n",
            "-----Fitting for attacker: 466-----Loss:0.5137659\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.3345 - accuracy: 0.8913 - val_loss: 0.0203 - val_accuracy: 0.9950\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0105 - accuracy: 0.9979 - val_loss: 0.0049 - val_accuracy: 0.9993\n",
            "-----Fitting for attacker: 468-----Loss:0.51099044\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.3363 - accuracy: 0.8933 - val_loss: 0.0163 - val_accuracy: 0.9960\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0082 - accuracy: 0.9983 - val_loss: 0.0034 - val_accuracy: 0.9997\n",
            "----------0.6----------\n",
            "-----Fitting for attacker: 102-----Loss:0.70042896\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.3410 - accuracy: 0.8901 - val_loss: 0.0380 - val_accuracy: 0.9900\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0292 - accuracy: 0.9903 - val_loss: 0.0181 - val_accuracy: 0.9953\n",
            "-----Fitting for attacker: 106-----Loss:0.65664184\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 8ms/step - loss: 0.3858 - accuracy: 0.8753 - val_loss: 0.0480 - val_accuracy: 0.9863\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 2s 8ms/step - loss: 0.0281 - accuracy: 0.9919 - val_loss: 0.0193 - val_accuracy: 0.9933\n",
            "-----Fitting for attacker: 109-----Loss:0.61134815\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.4401 - accuracy: 0.8600 - val_loss: 0.0393 - val_accuracy: 0.9897\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0264 - accuracy: 0.9929 - val_loss: 0.0134 - val_accuracy: 0.9963\n",
            "-----Fitting for attacker: 111-----Loss:0.62107074\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.4713 - accuracy: 0.8547 - val_loss: 0.0841 - val_accuracy: 0.9750\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0309 - accuracy: 0.9913 - val_loss: 0.0134 - val_accuracy: 0.9967\n",
            "-----Fitting for attacker: 115-----Loss:0.55497086\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.4759 - accuracy: 0.8510 - val_loss: 0.0529 - val_accuracy: 0.9867\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0261 - accuracy: 0.9933 - val_loss: 0.0233 - val_accuracy: 0.9930\n",
            "-----Fitting for attacker: 117-----Loss:0.52606535\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.4995 - accuracy: 0.8434 - val_loss: 0.0731 - val_accuracy: 0.9763\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0292 - accuracy: 0.9920 - val_loss: 0.0196 - val_accuracy: 0.9930\n",
            "-----Fitting for attacker: 256-----Loss:0.52189505\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.4140 - accuracy: 0.8656 - val_loss: 0.0285 - val_accuracy: 0.9927\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0157 - accuracy: 0.9964 - val_loss: 0.0125 - val_accuracy: 0.9973\n",
            "----------0.5----------\n",
            "-----Fitting for attacker: 102-----Loss:0.53473175\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.3911 - accuracy: 0.8757 - val_loss: 0.0425 - val_accuracy: 0.9850\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0242 - accuracy: 0.9940 - val_loss: 0.0125 - val_accuracy: 0.9963\n",
            "-----Fitting for attacker: 104-----Loss:0.4830511\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.3958 - accuracy: 0.8797 - val_loss: 0.0543 - val_accuracy: 0.9823\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0233 - accuracy: 0.9941 - val_loss: 0.0147 - val_accuracy: 0.9953\n",
            "-----Fitting for attacker: 108-----Loss:0.5609255\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.3775 - accuracy: 0.8850 - val_loss: 0.0262 - val_accuracy: 0.9950\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0156 - accuracy: 0.9959 - val_loss: 0.0071 - val_accuracy: 0.9983\n",
            "-----Fitting for attacker: 110-----Loss:0.5515542\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.3687 - accuracy: 0.8791 - val_loss: 0.0264 - val_accuracy: 0.9930\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0185 - accuracy: 0.9953 - val_loss: 0.0092 - val_accuracy: 0.9973\n",
            "-----Fitting for attacker: 112-----Loss:0.5723493\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 8ms/step - loss: 0.3756 - accuracy: 0.8834 - val_loss: 0.0286 - val_accuracy: 0.9923\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0153 - accuracy: 0.9960 - val_loss: 0.0146 - val_accuracy: 0.9970\n",
            "-----Fitting for attacker: 146-----Loss:0.6083967\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.4125 - accuracy: 0.8737 - val_loss: 0.0504 - val_accuracy: 0.9863\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0313 - accuracy: 0.9907 - val_loss: 0.0232 - val_accuracy: 0.9940\n",
            "-----Fitting for attacker: 150-----Loss:0.61190003\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.3596 - accuracy: 0.8809 - val_loss: 0.0330 - val_accuracy: 0.9917\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0159 - accuracy: 0.9957 - val_loss: 0.0257 - val_accuracy: 0.9937\n",
            "-----Fitting for attacker: 152-----Loss:0.65163195\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.3402 - accuracy: 0.8954 - val_loss: 0.0315 - val_accuracy: 0.9920\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0144 - accuracy: 0.9966 - val_loss: 0.0111 - val_accuracy: 0.9973\n",
            "-----Fitting for attacker: 154-----Loss:0.72663397\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.3176 - accuracy: 0.9093 - val_loss: 0.0217 - val_accuracy: 0.9950\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0098 - accuracy: 0.9971 - val_loss: 0.0098 - val_accuracy: 0.9977\n",
            "-----Fitting for attacker: 156-----Loss:0.71143985\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.2723 - accuracy: 0.9193 - val_loss: 0.0168 - val_accuracy: 0.9947\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0095 - accuracy: 0.9981 - val_loss: 0.0088 - val_accuracy: 0.9977\n",
            "-----Fitting for attacker: 204-----Loss:0.6633921\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.4360 - accuracy: 0.8639 - val_loss: 0.0519 - val_accuracy: 0.9840\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0258 - accuracy: 0.9937 - val_loss: 0.0207 - val_accuracy: 0.9943\n",
            "-----Fitting for attacker: 208-----Loss:0.6834948\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.4243 - accuracy: 0.8676 - val_loss: 0.0718 - val_accuracy: 0.9760\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0251 - accuracy: 0.9930 - val_loss: 0.0161 - val_accuracy: 0.9953\n",
            "-----Fitting for attacker: 211-----Loss:0.66420275\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.4164 - accuracy: 0.8754 - val_loss: 0.0460 - val_accuracy: 0.9873\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0265 - accuracy: 0.9910 - val_loss: 0.0267 - val_accuracy: 0.9913\n",
            "-----Fitting for attacker: 213-----Loss:0.7151745\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.4128 - accuracy: 0.8660 - val_loss: 0.0494 - val_accuracy: 0.9853\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0287 - accuracy: 0.9914 - val_loss: 0.0214 - val_accuracy: 0.9940\n",
            "----------0.4----------\n",
            "-----Fitting for attacker: 102-----Loss:0.95052135\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.3283 - accuracy: 0.8981 - val_loss: 0.0133 - val_accuracy: 0.9967\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0099 - accuracy: 0.9983 - val_loss: 0.0025 - val_accuracy: 0.9997\n",
            "-----Fitting for attacker: 104-----Loss:1.0368382\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.3154 - accuracy: 0.8996 - val_loss: 0.0108 - val_accuracy: 0.9977\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0125 - accuracy: 0.9966 - val_loss: 0.0027 - val_accuracy: 0.9997\n",
            "-----Fitting for attacker: 106-----Loss:0.9555261\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.3174 - accuracy: 0.9006 - val_loss: 0.0114 - val_accuracy: 0.9963\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0133 - accuracy: 0.9960 - val_loss: 0.0035 - val_accuracy: 0.9993\n",
            "-----Fitting for attacker: 112-----Loss:0.96416336\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.3116 - accuracy: 0.8989 - val_loss: 0.0180 - val_accuracy: 0.9947\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0114 - accuracy: 0.9969 - val_loss: 0.0021 - val_accuracy: 0.9993\n",
            "-----Fitting for attacker: 114-----Loss:1.0676386\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.3175 - accuracy: 0.9037 - val_loss: 0.0211 - val_accuracy: 0.9950\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0115 - accuracy: 0.9971 - val_loss: 0.0066 - val_accuracy: 0.9980\n",
            "-----Fitting for attacker: 117-----Loss:1.0249417\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.2995 - accuracy: 0.9084 - val_loss: 0.0159 - val_accuracy: 0.9967\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0108 - accuracy: 0.9974 - val_loss: 0.0070 - val_accuracy: 0.9980\n",
            "-----Fitting for attacker: 119-----Loss:1.0421003\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.3157 - accuracy: 0.9044 - val_loss: 0.0207 - val_accuracy: 0.9950\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0113 - accuracy: 0.9976 - val_loss: 0.0102 - val_accuracy: 0.9970\n",
            "-----Fitting for attacker: 121-----Loss:1.0516616\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.2976 - accuracy: 0.9120 - val_loss: 0.0163 - val_accuracy: 0.9957\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0142 - accuracy: 0.9956 - val_loss: 0.0104 - val_accuracy: 0.9977\n",
            "-----Fitting for attacker: 126-----Loss:1.0983022\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.3058 - accuracy: 0.9060 - val_loss: 0.0239 - val_accuracy: 0.9937\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0125 - accuracy: 0.9971 - val_loss: 0.0164 - val_accuracy: 0.9963\n",
            "----------0.3----------\n",
            "-----Fitting for attacker: 102-----Loss:1.4630624\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.2502 - accuracy: 0.9234 - val_loss: 0.0079 - val_accuracy: 0.9980\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0043 - accuracy: 0.9991 - val_loss: 0.0103 - val_accuracy: 0.9967\n",
            "-----Fitting for attacker: 104-----Loss:1.6422291\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.2665 - accuracy: 0.9199 - val_loss: 0.0055 - val_accuracy: 0.9990\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0087 - accuracy: 0.9979 - val_loss: 0.0065 - val_accuracy: 0.9983\n",
            "-----Fitting for attacker: 106-----Loss:1.5411155\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.2667 - accuracy: 0.9236 - val_loss: 0.0083 - val_accuracy: 0.9980\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0099 - accuracy: 0.9964 - val_loss: 0.0038 - val_accuracy: 0.9987\n",
            "-----Fitting for attacker: 108-----Loss:1.6474462\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.2571 - accuracy: 0.9250 - val_loss: 0.0096 - val_accuracy: 0.9973\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0072 - accuracy: 0.9983 - val_loss: 0.0024 - val_accuracy: 0.9993\n",
            "-----Fitting for attacker: 112-----Loss:1.6965371\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.2720 - accuracy: 0.9223 - val_loss: 0.0109 - val_accuracy: 0.9963\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0098 - accuracy: 0.9969 - val_loss: 0.0049 - val_accuracy: 0.9990\n",
            "-----Fitting for attacker: 114-----Loss:1.7138352\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.2977 - accuracy: 0.9109 - val_loss: 0.0347 - val_accuracy: 0.9910\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0100 - accuracy: 0.9974 - val_loss: 0.0147 - val_accuracy: 0.9947\n",
            "-----Fitting for attacker: 117-----Loss:1.7347219\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.2902 - accuracy: 0.9110 - val_loss: 0.0201 - val_accuracy: 0.9947\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0067 - accuracy: 0.9980 - val_loss: 0.0034 - val_accuracy: 0.9990\n",
            "-----Fitting for attacker: 120-----Loss:1.7746103\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.2956 - accuracy: 0.9101 - val_loss: 0.0145 - val_accuracy: 0.9943\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0083 - accuracy: 0.9979 - val_loss: 0.0054 - val_accuracy: 0.9990\n",
            "-----Fitting for attacker: 124-----Loss:1.7894478\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.3044 - accuracy: 0.9076 - val_loss: 0.0173 - val_accuracy: 0.9950\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0113 - accuracy: 0.9970 - val_loss: 0.0098 - val_accuracy: 0.9970\n",
            "-----Fitting for attacker: 126-----Loss:1.8460464\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.3043 - accuracy: 0.9056 - val_loss: 0.0165 - val_accuracy: 0.9950\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0105 - accuracy: 0.9979 - val_loss: 0.0055 - val_accuracy: 0.9987\n",
            "-----Fitting for attacker: 129-----Loss:1.7588265\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.2901 - accuracy: 0.9126 - val_loss: 0.0180 - val_accuracy: 0.9950\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0087 - accuracy: 0.9983 - val_loss: 0.0032 - val_accuracy: 0.9990\n",
            "-----Fitting for attacker: 136-----Loss:1.8296174\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.2705 - accuracy: 0.9156 - val_loss: 0.0261 - val_accuracy: 0.9910\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0102 - accuracy: 0.9981 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
            "-----Fitting for attacker: 138-----Loss:1.9727457\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 3s 10ms/step - loss: 0.2758 - accuracy: 0.9126 - val_loss: 0.0122 - val_accuracy: 0.9970\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 7ms/step - loss: 0.0056 - accuracy: 0.9990 - val_loss: 0.0078 - val_accuracy: 0.9980\n",
            "-----Fitting for attacker: 140-----Loss:1.9973481\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.2603 - accuracy: 0.9210 - val_loss: 0.0120 - val_accuracy: 0.9980\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0095 - accuracy: 0.9971 - val_loss: 0.0027 - val_accuracy: 0.9997\n",
            "-----Fitting for attacker: 142-----Loss:1.9397416\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.2632 - accuracy: 0.9170 - val_loss: 0.0101 - val_accuracy: 0.9987\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0083 - accuracy: 0.9983 - val_loss: 0.0027 - val_accuracy: 0.9990\n",
            "-----Fitting for attacker: 144-----Loss:1.867022\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.2801 - accuracy: 0.9149 - val_loss: 0.0141 - val_accuracy: 0.9970\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0088 - accuracy: 0.9971 - val_loss: 0.0026 - val_accuracy: 0.9993\n",
            "-----Fitting for attacker: 149-----Loss:2.0561047\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.2832 - accuracy: 0.9114 - val_loss: 0.0106 - val_accuracy: 0.9977\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0066 - accuracy: 0.9984 - val_loss: 0.0044 - val_accuracy: 0.9990\n",
            "-----Fitting for attacker: 152-----Loss:2.060264\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.2815 - accuracy: 0.9104 - val_loss: 0.0110 - val_accuracy: 0.9970\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0054 - accuracy: 0.9991 - val_loss: 0.0032 - val_accuracy: 0.9990\n",
            "-----Fitting for attacker: 155-----Loss:2.3620741\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.3292 - accuracy: 0.9006 - val_loss: 0.0112 - val_accuracy: 0.9977\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0066 - accuracy: 0.9987 - val_loss: 0.0025 - val_accuracy: 0.9997\n",
            "-----Fitting for attacker: 158-----Loss:2.0211315\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.3112 - accuracy: 0.9020 - val_loss: 0.0178 - val_accuracy: 0.9950\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0095 - accuracy: 0.9976 - val_loss: 0.0145 - val_accuracy: 0.9967\n",
            "-----Fitting for attacker: 165-----Loss:2.1260219\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.3422 - accuracy: 0.8907 - val_loss: 0.0162 - val_accuracy: 0.9977\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0061 - accuracy: 0.9984 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
            "-----Fitting for attacker: 167-----Loss:2.1588607\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.3511 - accuracy: 0.8894 - val_loss: 0.0107 - val_accuracy: 0.9990\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 7ms/step - loss: 0.0051 - accuracy: 0.9991 - val_loss: 0.0063 - val_accuracy: 0.9990\n",
            "-----Fitting for attacker: 171-----Loss:2.1549582\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.3701 - accuracy: 0.8859 - val_loss: 0.0113 - val_accuracy: 0.9973\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0054 - accuracy: 0.9993 - val_loss: 0.0018 - val_accuracy: 0.9997\n",
            "-----Fitting for attacker: 174-----Loss:2.0437474\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.3628 - accuracy: 0.8887 - val_loss: 0.0118 - val_accuracy: 0.9977\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0055 - accuracy: 0.9987 - val_loss: 0.0022 - val_accuracy: 0.9997\n",
            "-----Fitting for attacker: 177-----Loss:2.1999369\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.3810 - accuracy: 0.8786 - val_loss: 0.0098 - val_accuracy: 0.9987\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 7ms/step - loss: 0.0083 - accuracy: 0.9987 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "-----Fitting for attacker: 180-----Loss:2.1161683\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.3736 - accuracy: 0.8807 - val_loss: 0.0168 - val_accuracy: 0.9963\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0068 - accuracy: 0.9990 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
            "-----Fitting for attacker: 182-----Loss:2.2425935\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.3710 - accuracy: 0.8827 - val_loss: 0.0238 - val_accuracy: 0.9937\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0075 - accuracy: 0.9984 - val_loss: 0.0032 - val_accuracy: 0.9997\n",
            "-----Fitting for attacker: 184-----Loss:2.3702378\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.3811 - accuracy: 0.8819 - val_loss: 0.0258 - val_accuracy: 0.9940\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0104 - accuracy: 0.9970 - val_loss: 0.0034 - val_accuracy: 0.9997\n",
            "-----Fitting for attacker: 186-----Loss:2.0193121\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.3739 - accuracy: 0.8833 - val_loss: 0.0171 - val_accuracy: 0.9963\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0069 - accuracy: 0.9989 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
            "----------0.2----------\n",
            "-----Fitting for attacker: 101-----Loss:2.0817988\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.2847 - accuracy: 0.9096 - val_loss: 0.0101 - val_accuracy: 0.9977\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0075 - accuracy: 0.9979 - val_loss: 0.0017 - val_accuracy: 0.9993\n",
            "-----Fitting for attacker: 106-----Loss:2.144274\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.2809 - accuracy: 0.9143 - val_loss: 0.0065 - val_accuracy: 0.9983\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0049 - accuracy: 0.9989 - val_loss: 0.0087 - val_accuracy: 0.9980\n",
            "-----Fitting for attacker: 108-----Loss:2.1846306\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.2717 - accuracy: 0.9210 - val_loss: 0.0099 - val_accuracy: 0.9977\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0051 - accuracy: 0.9986 - val_loss: 0.0024 - val_accuracy: 0.9993\n",
            "-----Fitting for attacker: 110-----Loss:2.4263525\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.2713 - accuracy: 0.9161 - val_loss: 0.0110 - val_accuracy: 0.9967\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0046 - accuracy: 0.9991 - val_loss: 0.0027 - val_accuracy: 0.9993\n",
            "-----Fitting for attacker: 112-----Loss:2.262104\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.2817 - accuracy: 0.9129 - val_loss: 0.0079 - val_accuracy: 0.9973\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0069 - accuracy: 0.9983 - val_loss: 0.0017 - val_accuracy: 0.9997\n",
            "-----Fitting for attacker: 114-----Loss:2.387646\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.2976 - accuracy: 0.9071 - val_loss: 0.0076 - val_accuracy: 0.9973\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0069 - accuracy: 0.9977 - val_loss: 0.0055 - val_accuracy: 0.9987\n",
            "-----Fitting for attacker: 117-----Loss:2.4398053\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.2817 - accuracy: 0.9169 - val_loss: 0.0166 - val_accuracy: 0.9950\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0050 - accuracy: 0.9991 - val_loss: 0.0022 - val_accuracy: 0.9993\n",
            "-----Fitting for attacker: 119-----Loss:2.4932346\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.2910 - accuracy: 0.9153 - val_loss: 0.0061 - val_accuracy: 0.9987\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0043 - accuracy: 0.9987 - val_loss: 0.0017 - val_accuracy: 0.9997\n",
            "-----Fitting for attacker: 121-----Loss:2.6292107\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.3007 - accuracy: 0.9113 - val_loss: 0.0084 - val_accuracy: 0.9983\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0075 - accuracy: 0.9979 - val_loss: 0.0038 - val_accuracy: 0.9993\n",
            "-----Fitting for attacker: 123-----Loss:2.3603613\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.3121 - accuracy: 0.9059 - val_loss: 0.0074 - val_accuracy: 0.9987\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0041 - accuracy: 0.9993 - val_loss: 0.0026 - val_accuracy: 0.9990\n",
            "-----Fitting for attacker: 140-----Loss:2.611857\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 3s 10ms/step - loss: 0.3262 - accuracy: 0.9096 - val_loss: 0.0173 - val_accuracy: 0.9953\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.0063 - accuracy: 0.9986 - val_loss: 0.0032 - val_accuracy: 0.9993\n",
            "-----Fitting for attacker: 143-----Loss:2.62882\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.3298 - accuracy: 0.9003 - val_loss: 0.0082 - val_accuracy: 0.9987\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0052 - accuracy: 0.9989 - val_loss: 0.0021 - val_accuracy: 0.9993\n",
            "-----Fitting for attacker: 152-----Loss:2.7627306\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.3164 - accuracy: 0.9024 - val_loss: 0.0111 - val_accuracy: 0.9970\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0050 - accuracy: 0.9987 - val_loss: 0.0061 - val_accuracy: 0.9987\n",
            "-----Fitting for attacker: 156-----Loss:2.8295994\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.2977 - accuracy: 0.9124 - val_loss: 0.0109 - val_accuracy: 0.9977\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0054 - accuracy: 0.9990 - val_loss: 0.0042 - val_accuracy: 0.9990\n",
            "-----Fitting for attacker: 159-----Loss:2.9601552\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.2888 - accuracy: 0.9131 - val_loss: 0.0085 - val_accuracy: 0.9977\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0044 - accuracy: 0.9991 - val_loss: 0.0012 - val_accuracy: 0.9997\n",
            "-----Fitting for attacker: 162-----Loss:2.5999012\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.2725 - accuracy: 0.9203 - val_loss: 0.0050 - val_accuracy: 0.9987\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 0.0013 - val_accuracy: 0.9997\n",
            "----------0.1----------\n",
            "-----Fitting for attacker: 101-----Loss:3.7965114\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.3469 - accuracy: 0.8936 - val_loss: 0.0136 - val_accuracy: 0.9967\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0041 - accuracy: 0.9993 - val_loss: 0.0029 - val_accuracy: 0.9997\n",
            "-----Fitting for attacker: 104-----Loss:3.511621\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.3485 - accuracy: 0.8936 - val_loss: 0.0111 - val_accuracy: 0.9973\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0048 - accuracy: 0.9993 - val_loss: 0.0081 - val_accuracy: 0.9977\n",
            "-----Fitting for attacker: 107-----Loss:3.5807672\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.3754 - accuracy: 0.8824 - val_loss: 0.0144 - val_accuracy: 0.9973\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0060 - accuracy: 0.9984 - val_loss: 0.0068 - val_accuracy: 0.9987\n",
            "-----Fitting for attacker: 110-----Loss:3.4589195\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.3631 - accuracy: 0.8897 - val_loss: 0.0149 - val_accuracy: 0.9960\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0060 - accuracy: 0.9989 - val_loss: 0.0023 - val_accuracy: 0.9997\n",
            "-----Fitting for attacker: 112-----Loss:3.5170145\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.3608 - accuracy: 0.8876 - val_loss: 0.0081 - val_accuracy: 0.9983\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0056 - accuracy: 0.9984 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
            "-----Fitting for attacker: 116-----Loss:3.759663\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.3562 - accuracy: 0.8901 - val_loss: 0.0100 - val_accuracy: 0.9970\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0057 - accuracy: 0.9987 - val_loss: 0.0114 - val_accuracy: 0.9973\n",
            "-----Fitting for attacker: 118-----Loss:3.8294086\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.3651 - accuracy: 0.8860 - val_loss: 0.0098 - val_accuracy: 0.9973\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0054 - accuracy: 0.9986 - val_loss: 0.0063 - val_accuracy: 0.9977\n",
            "-----Fitting for attacker: 122-----Loss:3.6138754\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.3576 - accuracy: 0.8873 - val_loss: 0.0194 - val_accuracy: 0.9947\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0074 - accuracy: 0.9980 - val_loss: 0.0023 - val_accuracy: 0.9997\n",
            "-----Fitting for attacker: 145-----Loss:4.2942543\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.3355 - accuracy: 0.8991 - val_loss: 0.0050 - val_accuracy: 0.9990\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0064 - accuracy: 0.9987 - val_loss: 0.0014 - val_accuracy: 0.9997\n",
            "-----Fitting for attacker: 148-----Loss:4.1552444\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.3200 - accuracy: 0.9030 - val_loss: 0.0041 - val_accuracy: 0.9997\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.0015 - val_accuracy: 0.9997\n",
            "-----Fitting for attacker: 150-----Loss:4.04886\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.3490 - accuracy: 0.8921 - val_loss: 0.0039 - val_accuracy: 0.9997\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0041 - accuracy: 0.9991 - val_loss: 8.6228e-04 - val_accuracy: 1.0000\n",
            "-----Fitting for attacker: 153-----Loss:3.7522128\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.3565 - accuracy: 0.8884 - val_loss: 0.0081 - val_accuracy: 0.9987\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0024 - accuracy: 0.9999 - val_loss: 0.0018 - val_accuracy: 0.9997\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure()\n",
        "plt.plot(all_loss)"
      ],
      "metadata": {
        "id": "7TcF7RVjK8Ng",
        "outputId": "0d395088-1e1b-4c2a-d30f-f0193cd9f703",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "id": "7TcF7RVjK8Ng",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f17ffb1fed0>]"
            ]
          },
          "metadata": {},
          "execution_count": 41
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test_model_w_attacker():\n",
        "  #Prepare y values and random values for input to generator\n",
        "  rand_y_in = tf.experimental.numpy.append(test_labels, tf.random.normal([test_labels.shape[0], noise_dim]), axis=1)\n",
        "  \n",
        "  #Generate noises for rand_y_in\n",
        "  generated_noise = generator(rand_y_in, training=False)\n",
        "  generated_noise = generated_noise * 0.5\n",
        "  generated_noise = tf.squeeze(generated_noise)\n",
        "\n",
        "  #Add noises to x images\n",
        "  noisy_images = generated_noise.numpy()+test_images\n",
        "\n",
        "  #Create a new attacker model that has the same architecture as GAN discriminator, and try to fit to noisy x inputs\n",
        "  attacker_model = make_discriminator_model()\n",
        "  attacker_model.compile(optimizer=tf.keras.optimizers.Adam(),loss=cross_entropy_categorical,metrics=[\"accuracy\"])\n",
        "  return attacker_model.fit(noisy_images,test_labels,validation_split=0.3,epochs=2)"
      ],
      "metadata": {
        "id": "l3XRGQ5O2M_s"
      },
      "id": "l3XRGQ5O2M_s",
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_model_w_attacker()"
      ],
      "metadata": {
        "id": "LfUsANMEA9Hx",
        "outputId": "91fbefc6-172a-49b0-832b-345fe50e06c3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "LfUsANMEA9Hx",
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "219/219 [==============================] - 4s 15ms/step - loss: 0.3626 - accuracy: 0.8894 - val_loss: 0.0527 - val_accuracy: 0.9810\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0302 - accuracy: 0.9909 - val_loss: 0.0211 - val_accuracy: 0.9947\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f15603c2b90>"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history.history['val_loss'][-1]"
      ],
      "metadata": {
        "id": "DUVGKGXeBJO9",
        "outputId": "5cf188ff-d644-4760-b3cb-83ac244b409d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "DUVGKGXeBJO9",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0026047516148537397"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experiment (Test9)"
      ],
      "metadata": {
        "id": "8aC0VCNuYbfm"
      },
      "id": "8aC0VCNuYbfm"
    },
    {
      "cell_type": "code",
      "source": [
        "for lmbd in np.float32(np.linspace(0.9,0.1,9)):\n",
        "\n",
        "  print('----------'+str(lmbd)+'----------')\n",
        "\n",
        "  #Restart graph session\n",
        "  tf.keras.backend.clear_session()\n",
        "\n",
        "  #Generate New Models\n",
        "  generator = make_generator_model()\n",
        "  discriminator = make_discriminator_model()\n",
        "\n",
        "  #Set up optimizer and checkpoints(Never used, putting it here just in case)\n",
        "  checkpoint_dir = './training_checkpoints'\n",
        "  checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "  checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
        "                                  discriminator_optimizer=discriminator_optimizer,\n",
        "                                  generator=generator,\n",
        "                                  discriminator=discriminator)\n",
        "  \n",
        "  #Reset train_time to zero\n",
        "  train_time=0\n",
        "\n",
        "  #Initialize metric save arrays\n",
        "  norm_evals = []\n",
        "  disc_w_noise_accuracy = []\n",
        "  disc_wo_noise_accuracy = []\n",
        "  gen_loss_evals = []\n",
        "  disc_loss_evals = []\n",
        "  lambda_evals = []\n",
        "\n",
        "  #Start training with new lmbd number\n",
        "  train(dataset, EPOCHS,train_time,lmbd)\n",
        "\n",
        "  #Save arrays as csv file\n",
        "  df = pd.DataFrame(list(zip(norm_evals, disc_w_noise_accuracy,disc_wo_noise_accuracy,gen_loss_evals,disc_loss_evals)),\n",
        "                columns =['Generator Norm', 'Disc_acc (w/ noise)','Disc_acc (w/o noise)','Generator Loss','Discriminator Loss'])\n",
        "\n",
        "  df.to_csv(images_dir+'/'+str(lmbd)+'/out.csv',index=False)"
      ],
      "metadata": {
        "id": "KD7wDKHIYgSM"
      },
      "id": "KD7wDKHIYgSM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "cb2b8616-3f89-4d9a-8cf3-352b221f732f",
      "metadata": {
        "tags": [],
        "id": "cb2b8616-3f89-4d9a-8cf3-352b221f732f"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generator = make_generator_model()\n",
        "discriminator = make_discriminator_model()"
      ],
      "metadata": {
        "id": "lZGe-V8gWGh5"
      },
      "id": "lZGe-V8gWGh5",
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
        "                                 discriminator_optimizer=discriminator_optimizer,\n",
        "                                 generator=generator,\n",
        "                                 discriminator=discriminator)"
      ],
      "metadata": {
        "id": "aenoX3xAWSsF"
      },
      "id": "aenoX3xAWSsF",
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_time=0"
      ],
      "metadata": {
        "id": "vRL_URpUwNmf"
      },
      "id": "vRL_URpUwNmf",
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Initialize arrays to save metrics (to plot)\n",
        "norm_evals = []\n",
        "disc_w_noise_accuracy = []\n",
        "disc_wo_noise_accuracy = []\n",
        "gen_loss_evals = []\n",
        "disc_loss_evals = []\n",
        "lambda_evals = []"
      ],
      "metadata": {
        "id": "IGhqZoJpXjB9"
      },
      "id": "IGhqZoJpXjB9",
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "id": "d5d9b66b-aa37-4076-9d2f-83df4718fed5",
      "metadata": {
        "id": "d5d9b66b-aa37-4076-9d2f-83df4718fed5",
        "outputId": "1a5c250d-01dc-4804-be36-649dd332c039",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-138-9d2c95fdd534>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_time\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-25-3c8b818d922e>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(dataset, epochs, train_time, current_lambda)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mclear_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"2nd order Norm: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_norm_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerated_noise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Discriminator w/o Noise Accuracy: \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdisc_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Discriminator w/  Noise Accuracy: \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdisc_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mgenerated_noise\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-5434e1ba6bff>\u001b[0m in \u001b[0;36mgen_norm_mean\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mnorm_calculated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mord\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mnorm_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnorm_calculated\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mnorm_mean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1221\u001b[0m     \"\"\"\n\u001b[1;32m   1222\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1223\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1224\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1187\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1189\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1190\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "train(dataset, EPOCHS,train_time,0.3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "744fce29-db0a-428f-9529-2a93f0091b82",
      "metadata": {
        "id": "744fce29-db0a-428f-9529-2a93f0091b82"
      },
      "outputs": [],
      "source": [
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test Trained Generator"
      ],
      "metadata": {
        "id": "qDA_BURIyTSx"
      },
      "id": "qDA_BURIyTSx"
    },
    {
      "cell_type": "code",
      "source": [
        "#train_X = tf.cast(train_X, tf.float32)\n",
        "rand_y_in = tf.experimental.numpy.append(test_labels, tf.random.normal([test_labels.shape[0], noise_dim]), axis=1)\n",
        "\n",
        "generated_noise = generator(rand_y_in, training=False)\n",
        "generated_noise = generated_noise * 0.6\n",
        "generated_noise = tf.squeeze(generated_noise)\n",
        "generated_noise = generated_noise.numpy()"
      ],
      "metadata": {
        "id": "YZzDb1nGyd4N"
      },
      "id": "YZzDb1nGyd4N",
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index = 12\n",
        "#print(rand_y_in[index])\n",
        "fig = plt.figure(figsize=(12, 10))\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.imshow(test_images[index, :, :], cmap='gray',vmin=0, vmax=1.5)\n",
        "plt.title('x_i')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.imshow(generated_noise[index, :, :], cmap='gray',vmin=0, vmax=1.5)\n",
        "plt.title('G(y_i)')\n",
        "plt.axis('off')\n",
        "\n",
        "\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.imshow(test_images[index, :, :]+generated_noise[index, :, :], cmap='gray',vmin=0, vmax=1.5)\n",
        "plt.title('x_i + G(y_i)')\n",
        "plt.axis('off')\n",
        "\n",
        "print(np.max(generated_noise[index]+generated_noise[index, :, :]))"
      ],
      "metadata": {
        "id": "U_iTnqCiySfN",
        "outputId": "ce8fc3fa-a9a3-4c29-a696-351badc85d14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        }
      },
      "id": "U_iTnqCiySfN",
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.1938596\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x720 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "noisy_images = generated_noise.numpy()+test_images\n",
        "attacker_model = make_discriminator_model()\n",
        "attacker_model.compile(optimizer=tf.keras.optimizers.Adam(),loss=cross_entropy_categorical,metrics=[\"accuracy\"])\n",
        "attacker_model.fit(noisy_images,test_labels,validation_split=0.3,epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VREaDyBiziko",
        "outputId": "6b7891fa-4f95-4696-d0b8-9220157622bf"
      },
      "id": "VREaDyBiziko",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "219/219 [==============================] - 4s 11ms/step - loss: 0.1560 - accuracy: 0.9526 - val_loss: 0.0053 - val_accuracy: 0.9987\n",
            "Epoch 2/10\n",
            "219/219 [==============================] - 2s 9ms/step - loss: 0.0043 - accuracy: 0.9989 - val_loss: 0.0057 - val_accuracy: 0.9990\n",
            "Epoch 3/10\n",
            "219/219 [==============================] - 2s 8ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.0039 - val_accuracy: 0.9987\n",
            "Epoch 4/10\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 2.9413e-04 - accuracy: 1.0000 - val_loss: 8.7832e-04 - val_accuracy: 0.9997\n",
            "Epoch 5/10\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 8.3875e-05 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 0.9997\n",
            "Epoch 6/10\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 5.9417e-05 - accuracy: 1.0000 - val_loss: 9.2252e-04 - val_accuracy: 0.9997\n",
            "Epoch 7/10\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 4.5288e-05 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 0.9997\n",
            "Epoch 8/10\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 4.2503e-05 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 0.9997\n",
            "Epoch 9/10\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 3.0710e-05 - accuracy: 1.0000 - val_loss: 5.6159e-04 - val_accuracy: 0.9997\n",
            "Epoch 10/10\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 2.9020e-05 - accuracy: 1.0000 - val_loss: 8.7026e-04 - val_accuracy: 0.9997\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc87807c750>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generated_image = generator(seed, training=False)\n",
        "generated_image[7, :, :, 0].shape#\n",
        "\n",
        "plt.imshow(generated_image[7, :, :, 0], cmap='gray')\n",
        "plt.axis('off')"
      ],
      "metadata": {
        "id": "k11ZGpNVuMq4",
        "outputId": "14a125af-0160-46c3-f086-f5a46316095f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        }
      },
      "id": "k11ZGpNVuMq4",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-0.5, 27.5, 27.5, -0.5)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generated_image = generator(seed, training=False)\n",
        "\n",
        "plt.imshow(generated_image[7, :, :, 0], cmap='gray')\n",
        "generated_image[7, 27, 27, 0]"
      ],
      "metadata": {
        "id": "818GY4-OKTXr",
        "outputId": "fefce363-149d-4e65-f912-f84fd8aea51f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "id": "818GY4-OKTXr",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=0.5007884>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAYxElEQVR4nO2de3CV5bXGn0WIIOEmFyFgyk1AEQvaiDjgEVu0gBd0tF5qW7XtQUc7laozp9W22GlnZMTL+IcwUqWC4qVTRLBShAO0DFrBwICAV0TCRe73OyRZ549szqGa93nT7LB35rzPbyaTZD975Xvz7f3k29nrXWuZu0MI8f+fRvlegBAiN8jsQiSCzC5EIsjsQiSCzC5EIjTO5cGKioq8devWQb1RI/63p7KyMqgVFBTUObY2VFRUBLXGjflpjGU8YnrsvBw/fjyoZbu2bOOrqqrqHGtmVGePCQA0a9aszrGx50tsbdmc19ja2M/et28fDh8+XOPisjK7mQ0D8DSAAgDPuftYdv/WrVvj7rvvDurNmzenx9u9e3dQa9WqFY09cOAA1WMP7o4dO4Jau3btaCwzY22OzZ60APDll18GtTPPPJPGHjlyhOrZxjM9dl6aNGlC9S1btlD9W9/6VlBjzyUA2LNnD9VjfwRjhm3btm1Q27VrF41l523q1KlBrc4v482sAMAzAIYD6APgVjPrU9efJ4Q4tWTzP/sAAGvcfa27HwPwKoCR9bMsIUR9k43ZOwPYcNL3GzO3/QtmNsrMysys7ODBg1kcTgiRDaf83Xh3n+jupe5eWlRUdKoPJ4QIkI3ZNwEoOen7szK3CSEaINmY/X0APc2sm5mdBuAWADPrZ1lCiPqmzqk3d68ws58BeBvVqbdJ7r46Fsfyk7GUA0sDHT16lMZ2796d6uXl5VRn+wPOOOMMGhtL+8XSW7HU3OWXXx7UVq5cSWPnz59P9U6dOlE9dl5ZWjC2NyKWvorFr1+/PqiVlpbS2CVLllC9Y8eOVI895vv37w9qp59+Oo1t2rRpUGPnJKs8u7vPAjArm58hhMgN2i4rRCLI7EIkgswuRCLI7EIkgswuRCLI7EIkQk7r2c0MhYWFQf3QoUM0fuPGjUGN5R4B4NixY1Tv27cv1Z9//vmgxvLcALBpE99YyH4vAOjc+WslB//CrFnh7GfsnMbW/s4771C9S5cuVGd5+lgZKXuuADxXHYuPlUTv3LmT6iUlJVRftmwZ1QcPHhzU2N4EIF7yHEJXdiESQWYXIhFkdiESQWYXIhFkdiESQWYXIhFymnqrqqoCa03FuoECwOrV4QraWGqtffv2VP/kk0+ofv755we1WKllrGsuS8MAwNatW6nO0kSxFFEsfdWvXz+qr127luosJXrFFVfQ2AULFlA91uaMnbfYYxZ7TJYuXUr1WMk1awfdsmVLGlvXEldd2YVIBJldiESQ2YVIBJldiESQ2YVIBJldiESQ2YVIhJzm2Rs1akRzzqz1LwB8/vnnQe3SSy+lsatWraJ6rH0vy2XHYmN7AF555RWqx1pVs3LNNWvW0Nhzzz2X6rE8Ott/AABPPvlkUOvTh88B/eKLL6gemyC7bt26Oh/73Xffpfo555xD9eXLl1N94MCBQW3GjBk0lpUGswmvurILkQgyuxCJILMLkQgyuxCJILMLkQgyuxCJILMLkQjG6mrrmw4dOvhtt90W1GO11yzPHhuhG6tnj8Fy6WwMNQC0bduW6rFW0rGRzosXLw5qjRvzrRR//etfqf6rX/2K6rG68N27dwe1WDvnWB3/p59+SnW292LHjh00Ntb+O1bn//HHH1OdPddjvRXY8+npp5/Ghg0banxCZrWpxszWAdgPoBJAhbvzoddCiLxRHzvoLnd3/mdSCJF39D+7EImQrdkdwBwzW2pmo2q6g5mNMrMyMys7fPhwlocTQtSVbF/GD3b3TWZ2JoC5Zvaxuy88+Q7uPhHARKD6DbosjyeEqCNZXdndfVPm8zYA0wEMqI9FCSHqnzqb3cyKzKzFia8BXAmA15EKIfJGNi/jOwCYnskxNwbwsrvPZgEFBQUoKioK6tn0fo/VNsdqhK+++mqql5eXB7XY2OJYrvqqq66ieqwm/e677w5q48aNo7HDhw+nOvu9gfh5ZSOh9+3bR2Njdfy9evWi+q5du4Lahg0baGybNm2o3qJFC6pv3ryZ6itWrAhqsfHhbH8B80Gdze7uawHwnQVCiAaDUm9CJILMLkQiyOxCJILMLkQiyOxCJEJOW0mbGZo0aRLUY6mUlStXBrVYKoWVWgLxVMuFF14Y1J599lka+9Of/pTqLEUEAMXFxVQfM2ZMUGvdujWNvfLKK6n+4YcfUj022rhbt25BLdbOecqUKVRfuHAh1VlacciQITT2hRdeoPpLL71EdTZWGQDuv//+oLZ3714aW1VVFdQKCwuDmq7sQiSCzC5EIsjsQiSCzC5EIsjsQiSCzC5EIsjsQiRCTvPs7o6jR48G9WXLltF4Vur5/e9/n8ZOmDCB6vPnz6c6y1fffvvtNPbBBx+k+siRI6nOyiEBnuuOxb7//vtUj5VqDho0iOpTp04NarGyZLavAgBuuOEGqrPy29JS3gg51np8xIgRVI+NfJ49O1wNftZZZ9FYtu9CeXYhhMwuRCrI7EIkgswuRCLI7EIkgswuRCLI7EIkQk5HNhcXFzvLSbdr147Gsxa6LH8PxPOqXbt2pTrLbY4fP57GDhjAZ2fE8qp///vfqb59+/agFqulnz59OtVjfQAuvvhiqh88eDCoxR7v2DjoH/zgB1Rna7/jjjtobIcOHagee0yvvfZaqv/+978PakOHDqWxbO/Do48+ivLy8hpHNuvKLkQiyOxCJILMLkQiyOxCJILMLkQiyOxCJILMLkQi5LSevaKiAnv27AnqZ599No3v2LFjUIuN912yZAnVr7jiCqq//fbbQe2b3/wmjY31N+/fvz/V2e8N8Fx5q1ataGwsj15ZWUn1tWvXUp2d91jP+pKSEqrHRmEvXbo0qP385z+nsW+88QbVW7ZsSfXY/oUePXoEtcmTJ9PYYcOGUT1E9MpuZpPMbJuZrTrptjZmNtfMPst85k4TQuSd2ryMfwHAV/+U/BLAPHfvCWBe5nshRAMmanZ3Xwjgq/OJRgI48VpjMoDr6nldQoh6pq5v0HVw9xMbdLcACG4kNrNRZlZmZmWxnmNCiFNH1u/Ge3UlTbCaxt0nunupu5fGht0JIU4ddTX7VjMrBoDM5231tyQhxKmgrmafCeBErertAMI9e4UQDYJont3MXgEwBEA7M9sIYAyAsQD+bGY/AVAO4KbaHKyoqAgXXXRRUGc5eADYsWNHUIvl2Tt37kz12Bxy1rM+Vvscq1ePsX//fqpfdtllQS1W5x+ry16wYAHVY+fdrMbSagDAj3/8Yxr74osvUv348eNUZ+d9zpw5NDaWR4/1CfjNb35Ddbb/4cILL6SxLVq0CGqsB0DU7O5+a0D6TixWCNFw0HZZIRJBZhciEWR2IRJBZhciEWR2IRIhpyWuhw8fxurVq4P61VdfTePnzZsX1GItjWPjf2M6Swv27t2bxm7ZsoXqffv2pfrnn39O9fPOOy+oTZs2jcbu2vXVsod/5aqrrqJ6rEz1oYceqpMGxFOxN954I9VfffXVoHbddbyc47333qP6nXfeSfWnnnqK6mPHjg1qsRbaU6ZMCWo7d+4MarqyC5EIMrsQiSCzC5EIMrsQiSCzC5EIMrsQiSCzC5EIOR3ZXFJS4qNHjw7qbdq0ofGNGoX/NsVy2bGWyXv37qU6y2UXFhbS2KKiIqq/9tprVGdjrgFg3LhxQW3UqFE0dv369VRnLY+BeJnp4sWLg1osR79s2TKqsxHeAB+bHNtXEXvMYu3Dy8rKqF5RURHUYuXWvXr1CmpTp07F1q1bNbJZiJSR2YVIBJldiESQ2YVIBJldiESQ2YVIBJldiETIaT378ePHaT782LFjNJ7VXl9yySU09vXXX6d6bCwya/0by8kuX76c6ueeey7VZ8+eTfURI0YEtVgt/IwZvOV/7Lw2a9aM6qw2e+PGjTR2+/btVI/l+Fn/g4EDB9JYtj8AALp27Ur12L6Pw4cPB7VYDr+4uDioNWnSJKjpyi5EIsjsQiSCzC5EIsjsQiSCzC5EIsjsQiSCzC5EIuQ0z25mNA/Yvn17Gl9eXh7UVqxYQWNjtfIsVw3wGuOXX36Zxg4fPpzqzZs3p/ratWupPmHChKD2i1/8gsaOHDmS6rHRxaz/OQCMGTMmqN1yyy00Njb2ODbKun///kEtVjPevXt3qrPx4UB8RDh7zGMjm9l+E9ZbIXplN7NJZrbNzFaddNsjZrbJzJZnPrhThBB5pzYv418AMKyG259y9/6Zj1n1uywhRH0TNbu7LwTAZwQJIRo82bxB9zMz+yDzMv+M0J3MbJSZlZlZ2aFDh7I4nBAiG+pq9gkAegDoD2AzgCdCd3T3ie5e6u6lsaIJIcSpo05md/et7l7p7lUA/ghgQP0uSwhR39TJ7GZ2co3d9QBWhe4rhGgYRPPsZvYKgCEA2pnZRgBjAAwxs/4AHMA6AHfV5mCVlZV05nashz3LTcZy9LE+4bNm8YRC06ZNgxrr4w0ACxcupPpdd/HTF6v7ZvO6J02aRGNZXTUAdOnSheo333wz1d96662gFstF9+vXj+otWrSg+vjx44Na7PF+5513qB7L08fy8N/97neD2oIFC2gse66znhBRs7v7rTXc/HwsTgjRsNB2WSESQWYXIhFkdiESQWYXIhFkdiESIacjmzt16uRshHDfvn1pPCuPjaVShg4dSvVYmSlra7xo0SIay9pQA8B7771H9WeffZbq7777blCLtSW+9957qf7rX/+a6m+++SbVWQrqnHPOobFffPEF1R9++GGqs/LcWEnzb3/7W6r37NmT6rFUb1VVVVBjjyfAxz3PnDkTO3bs0MhmIVJGZhciEWR2IRJBZhciEWR2IRJBZhciEWR2IRIhp3n2kpISf+CBB4J6p06daDxrJR0bmxzLe15wwQVUZ7nw2Kjpyy+/nOq7d++meqzEtXfv3kHtpZdeorHXX3891WPtmisrK6nOWjJPnDiRxrJW0ABw0UUXUX3atGlB7Z577qGxv/vd76h+6601FYP+H6tW8RYPrPV5Nu29n3jiCWzYsEF5diFSRmYXIhFkdiESQWYXIhFkdiESQWYXIhFkdiESIacjm6uqqnDgwIGgfsYZwSlSAPjo4jVr1kSPzYjl+NmYXFZnD1SPqmbEaqNjbYmXL18e1GI5/m9/+9tUf+yxx6geqwufP39+UHv00Udp7Isvvkj1efPmUf2SSy4JarER3rFx0rG9D+eff36d9VgbazYCvKCgIKjpyi5EIsjsQiSCzC5EIsjsQiSCzC5EIsjsQiSCzC5EIuQ0z+7utP45NgZ3/fr1Qa1Pnz409ssvv6T63LlzqT5o0KCgxursAeD111+neiwXHlv79773vaAWG//7l7/8hepbtmyh+umnn051VusfO2/f+MY3qB7bW8Hy8GxkMhDflxHjH//4B9VZnX/s9166dGlQO3ToUFCLXtnNrMTMFpjZh2a22szuy9zexszmmtlnmc98R4wQIq/U5mV8BYAH3L0PgIEA7jWzPgB+CWCeu/cEMC/zvRCigRI1u7tvdvdlma/3A/gIQGcAIwFMztxtMoDrTtUihRDZ82+9QWdmXQFcAGAxgA7uvjkjbQHQIRAzyszKzKyM/T8hhDi11NrsZtYcwDQAo91938maV3etrLFzpbtPdPdSdy9t1qxZVosVQtSdWpndzApRbfSp7n7ireWtZlac0YsBbDs1SxRC1AfR1JtV12c+D+Ajd3/yJGkmgNsBjM18nhH7WQUFBXR88cGDB2k8K8d85plnaOzAgQOp3qNHD6qz1sCXXnopjb3mmmuo/tprr1GdldcCwGeffRbUYm2uY2XFsVHXjRvzpxArgX388cdp7ODBg6l+5513Up2Vik6fPp3GxsZFHzlyhOpdu3al+iOPPBLUYu2/y8rKghpLGdYmzz4IwA8BrDSzE4XTD6Ha5H82s58AKAdwUy1+lhAiT0TN7u6LAIS6L3ynfpcjhDhVaLusEIkgswuRCDK7EIkgswuRCDK7EImQ0xLXY8eO0TLVLl260PgNGzYEtZtvvpnGsuMCQK9evaj+pz/9KajF8sGTJk2ietu2bakeG03M8uyxcdCrV6+m+v333091dl4AoG/fvkEtVpYcG7N98cUXU71169ZBLTZSOfaYxvYnsJbpAPCHP/whqMVai7MS2NNOOy2o6couRCLI7EIkgswuRCLI7EIkgswuRCLI7EIkgswuRCLkNM9eWFiI4uLiOsd36FBj5ysAQMuWLWlsrDVw06ZNqc5q1p944gkay9pQA0C/fv2o/txzz1GdtRa+7777aOzo0aOpHvvdYrX8LFf+4IMP0thYXfecOXOo3q1bt6A2atQoGjtz5kyqx/YAxGrtq5s71cyKFStoLGvvxvoX6MouRCLI7EIkgswuRCLI7EIkgswuRCLI7EIkgswuRCLkNM8O8Hz3/v37aey6deuCWqzme/HixVQfNmwY1VkuO1YL36RJE6rH4m+6iXfpZrXV1W3/w4wfP57qx48fp3psf8KSJUuC2qJFi2hsbJT1P//5T6q/+eabQW3AgAE0NrY3ItaPn/WsB4DS0tKg9re//Y3Gsjp9hq7sQiSCzC5EIsjsQiSCzC5EIsjsQiSCzC5EIsjsQiRCbeazlwCYAqADAAcw0d2fNrNHAPwngO2Zuz7k7rPYz3J3HD16NKg3a9aMrqVNmzZBbe/evTS2c+fOVL/nnnuozvKisX737HcGgNmzZ1O9e/fuVN++fXtQi/U/j9VOx/Y+TJ06leo33HBDUNu4cSONbdSIX4t69+5N9ZKSkqA2ZswYGnvNNddQPdt6dkb79u2pXlhYGNTYOavNppoKAA+4+zIzawFgqZnNzWhPufvjtfgZQog8U5v57JsBbM58vd/MPgLAL5NCiAbHv/U/u5l1BXABgBN7T39mZh+Y2SQzq3HPppmNMrMyMys7ePBgVosVQtSdWpvdzJoDmAZgtLvvAzABQA8A/VF95a+xWZm7T3T3UncvLSoqqoclCyHqQq3MbmaFqDb6VHd/HQDcfau7V7p7FYA/AuCVBUKIvBI1u1WXTT0P4CN3f/Kk209uE3s9AD4WUwiRV2rzbvwgAD8EsNLMlmduewjArWbWH9XpuHUA7or9oIKCArRq1Sqol5eX03g2dnnIkCE0lh0X4G2HAWDPnj1BjbW4BoDzzjuP6h9//HFW+m233RbU9u3bR2NjKctYPBsRDAAfffRRUGOpVABYtmwZ1WOwlGUsbbdz506q/+hHP6J6rDSYjR+P/bvbv3//oPbWW28Ftdq8G78IQE1F0TSnLoRoWGgHnRCJILMLkQgyuxCJILMLkQgyuxCJILMLkQg5bSVdWVkJtj/+7LPPpvEVFRVBbc2aNTSWlTsC8dHGL7/8clBbsGABjS0oKKB6LA9/5MgRqu/atSuodezYkcbeeOONVB83bhzV2fhgABg6dGhQu+yyy2hsrB3zjBkzqN6zZ8+gdu2119LYWbN4ZvmNN96gemwMN9ubEWslzfYPVFZWBjVd2YVIBJldiESQ2YVIBJldiESQ2YVIBJldiESQ2YVIBHP33B3MbDuAk4vW2wHYkbMF/Hs01LU11HUBWltdqc+1dXH3GntR59TsXzu4WZm7hxuy55GGuraGui5Aa6sruVqbXsYLkQgyuxCJkG+zT8zz8RkNdW0NdV2A1lZXcrK2vP7PLoTIHfm+sgshcoTMLkQi5MXsZjbMzD4xszVm9st8rCGEma0zs5VmttzMyvK8lklmts3MVp10Wxszm2tmn2U+1zhjL09re8TMNmXO3XIzG5GntZWY2QIz+9DMVpvZfZnb83ruyLpyct5y/j+7mRUA+BTAFQA2AngfwK3u/mFOFxLAzNYBKHX3vG/AMLP/AHAAwBR375u57TEAu9x9bOYP5Rnu/l8NZG2PADiQ7zHemWlFxSePGQdwHYA7kMdzR9Z1E3Jw3vJxZR8AYI27r3X3YwBeBTAyD+to8Lj7QgBfbUMzEsDkzNeTUf1kyTmBtTUI3H2zuy/LfL0fwIkx43k9d2RdOSEfZu8M4OTZNxvRsOa9O4A5ZrbUzEblezE10MHdN2e+3gKAz57KPdEx3rnkK2PGG8y5q8v482zRG3RfZ7C7XwhgOIB7My9XGyRe/T9YQ8qd1mqMd66oYcz4/5LPc1fX8efZkg+zbwJwcvfHszK3NQjcfVPm8zYA09HwRlFvPTFBN/N5W57X8780pDHeNY0ZRwM4d/kcf54Ps78PoKeZdTOz0wDcAmBmHtbxNcysKPPGCcysCMCVaHijqGcCuD3z9e0AeIvVHNJQxniHxowjz+cu7+PP3T3nHwBGoPod+c8BPJyPNQTW1R3AiszH6nyvDcArqH5ZdxzV7238BEBbAPMAfAbgvwG0aUBrexHASgAfoNpYxXla22BUv0T/AMDyzMeIfJ87sq6cnDdtlxUiEfQGnRCJILMLkQgyuxCJILMLkQgyuxCJILMLkQgyuxCJ8D8eoHF/SeJvWAAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate_and_save_images(generator, seed)"
      ],
      "metadata": {
        "id": "-6JrxUXX3GhO",
        "outputId": "16a55abd-68ce-4129-d772-4b2aa323da41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        }
      },
      "id": "-6JrxUXX3GhO",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x576 with 9 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for x,y in dataset:\n",
        "  mean_tensor_single = tf.math.reduce_mean(y,axis=1)\n",
        "  print(mean_tensor_single)\n",
        "  mean_tensor_multi = tf.stack([mean_tensor_single,mean_tensor_single,mean_tensor_single,mean_tensor_single,mean_tensor_single,mean_tensor_single,mean_tensor_single,mean_tensor_single,mean_tensor_single,mean_tensor_single],axis=1)\n",
        "  print(mean_tensor_multi.shape)\n",
        "  break"
      ],
      "metadata": {
        "id": "41TOXMixbJkj",
        "outputId": "2ba3bc13-7529-4560-e7bd-91f0dff79bc7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "41TOXMixbJkj",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
            " 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
            " 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
            " 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
            " 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
            " 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
            " 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
            " 0.1 0.1], shape=(128,), dtype=float32)\n",
            "(128, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "DFx1uh0tbzEj"
      },
      "id": "DFx1uh0tbzEj",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "name": "NoiseGAN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}